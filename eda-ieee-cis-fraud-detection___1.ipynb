{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-25T15:39:39.095061Z",
     "iopub.status.busy": "2026-01-25T15:39:39.094705Z",
     "iopub.status.idle": "2026-01-25T15:39:40.487456Z",
     "shell.execute_reply": "2026-01-25T15:39:40.486685Z",
     "shell.execute_reply.started": "2026-01-25T15:39:39.095025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ieee-fraud-detection/sample_submission.csv\n",
      "/kaggle/input/ieee-fraud-detection/test_identity.csv\n",
      "/kaggle/input/ieee-fraud-detection/train_identity.csv\n",
      "/kaggle/input/ieee-fraud-detection/test_transaction.csv\n",
      "/kaggle/input/ieee-fraud-detection/train_transaction.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE-CIS Fraud Detection Model\n",
    "\n",
    "## 1. Project Overview\n",
    "This project aims to build a robust machine learning model to detect fraudulent online transactions. Using the IEEE-CIS Fraud Detection dataset, we focus on advanced feature engineering to extract hidden patterns from anonymized and raw transaction data. The pipeline includes data preprocessing, extensive feature generation, memory optimization, and model training using LightGBM.\n",
    "\n",
    "## 2. Dataset Description\n",
    "The dataset is provided by Vesta Corporation, a leading payment service provider. It consists of two primary tables:\n",
    "- **Transaction Table:** Contains transaction details like amount (`TransactionAmt`), product code (`ProductCD`), card information (`card1`-`card6`), address (`addr1`, `addr2`), email domains (`P_emaildomain`, `R_emaildomain`), and time delta (`TransactionDT`).\n",
    "- **Identity Table:** Contains network and device information (IP, ISP, DeviceType, DeviceInfo, etc.) for a subset of transactions.\n",
    "\n",
    "Key challenges include:\n",
    "- **Class Imbalance:** Fraudulent transactions are a tiny fraction of the total (approx. 3.5%).\n",
    "- **Anonymization:** Many features (V-columns, ID-columns) are masked, requiring statistical aggregation rather than semantic interpretation.\n",
    "- **High Dimensionality:** Over 400 raw features, which we expand further through engineering.\n",
    "\n",
    "## 3. Importance of Fraud Detection\n",
    "In the digital economy, fraud detection is critical for:\n",
    "- **Financial Security:** Preventing direct financial losses from chargebacks and stolen goods.\n",
    "- **User Trust:** Ensuring customers feel safe transacting on the platform.\n",
    "- **Operational Efficiency:** Reducing the manual review workload by automating risk scoring.\n",
    "\n",
    "## 4. Feature Engineering Strategy\n",
    "To tackle these challenges, we implement:\n",
    "- **Transaction Amounts:** Log transforms, decimal extraction, and round-number flags to detect bot behavior.\n",
    "- **Time:** Cyclical features (hour of day), day of week, and business hours flagging.\n",
    "- **Card & Interaction:** Combining card types with locations and amounts to create unique user signatures.\n",
    "- **Email Analysis:** Differentiating business vs. personal emails and checking for domain mismatches.\n",
    "- **Device/Browser Fingerprinting:** Identifying specific OS/Browser combinations often used by fraud farms.\n",
    "- **Aggregations:** Calculating user \"velocity\" (mean/std of amounts) to detect spikes in activity.\n",
    "- **V-System (Vesta):** Statistical aggregation of correlated anonymous columns to reduce noise.\n",
    "\n",
    "- **Target Variable:** `isFraud` (Binary: 0 = Legitimate, 1 = Fraud)\n",
    "- **Evaluation Metric:** ROC-AUC (Area Under the Receiver Operating Characteristic Curve)\n",
    "#\n",
    "### Why ROC-AUC for Fraud Detection?\n",
    "From a Data Science perspective, we select ROC-AUC over standard metrics like Accuracy for three critical reasons:\n",
    "1.  **Robustness to Class Imbalance:** In this dataset, fraud represents only ~3.5% of cases. A trivial model predicting \"Legitimate\" for every transaction would achieve ~96.5% accuracy but have zero predictive power. ROC-AUC is insensitive to this imbalance, focusing instead on the model's ability to separate the signal (fraud) from the noise (legitimate).\n",
    "2.  **Threshold Independence:** Unlike F1-score or Accuracy which depend on a specific classification threshold (e.g., 0.5), ROC-AUC evaluates the model's ranking ability across *all* possible thresholds. This allows business stakeholders to trade off False Positives (blocking good users) against False Negatives (missing fraud) dynamically.\n",
    "3.  **Probabilistic Interpretation:** ROC-AUC represents the probability that the model ranks a randomly chosen fraudulent transaction higher than a randomly chosen legitimate one. This ranking capability is essential for prioritizing manual review queues.\n",
    "\n",
    "## 5. Resources\n",
    "- **Competition Overview:** https://www.kaggle.com/competitions/ieee-fraud-detection/overview\n",
    "- **Dataset:** https://www.kaggle.com/competitions/ieee-fraud-detection/data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries üìö\n",
    "\n",
    "**Why these libraries?**\n",
    "\n",
    "| Library | Purpose |\n",
    "|---------|---------|\n",
    "| `numpy` | Fast mathematical operations on arrays |\n",
    "| `pandas` | Data manipulation and analysis (DataFrames) |\n",
    "| `matplotlib` & `seaborn` | Data visualization (plots and charts) |\n",
    "| `sklearn` | Machine learning tools (train/test split, metrics, encoding) |\n",
    "| `lightgbm` | Gradient boosting model (fast and handles missing values well) |\n",
    "| `scipy` | Statistical functions |\n",
    "| `gc` | Garbage collection to free memory |\n",
    "\n",
    "We also set `warnings.filterwarnings('ignore')` to hide unnecessary warning messages and `pd.set_option('display.max_columns', 100)` to see more columns when viewing DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:39:40.490028Z",
     "iopub.status.busy": "2026-01-25T15:39:40.489246Z",
     "iopub.status.idle": "2026-01-25T15:39:48.276485Z",
     "shell.execute_reply": "2026-01-25T15:39:48.275668Z",
     "shell.execute_reply.started": "2026-01-25T15:39:40.489984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Loading üìÇ\n",
    "\n",
    "**What we're loading:**\n",
    "- `train_transaction.csv` - 590,540 transactions with 394 features (has `isFraud` target)\n",
    "- `test_transaction.csv` - 506,691 transactions with 393 features (no target - we predict this)\n",
    "- `train_identity.csv` - 144,233 identity records with 41 features\n",
    "- `test_identity.csv` - 141,907 identity records with 41 features\n",
    "\n",
    "**Key point:** Not all transactions have identity data! Only about 24% of transactions have matching identity information (device, browser, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:39:48.278039Z",
     "iopub.status.busy": "2026-01-25T15:39:48.277420Z",
     "iopub.status.idle": "2026-01-25T15:40:28.887589Z",
     "shell.execute_reply": "2026-01-25T15:40:28.886859Z",
     "shell.execute_reply.started": "2026-01-25T15:39:48.278016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Readed!\n",
      "Shape of train_transaction: (590540, 394)\n",
      "Shape of test_transaction: (506691, 393)\n",
      "\n",
      "Shape of train_identity: (144233, 41)\n",
      "Shape of test_transaction: (141907, 41)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "path = '/kaggle/input/ieee-fraud-detection'\n",
    "\n",
    "train_transaction = pd.read_csv(os.path.join(path,'train_transaction.csv'))\n",
    "test_transaction = pd.read_csv(os.path.join(path,'test_transaction.csv'))\n",
    "train_identity = pd.read_csv(os.path.join(path,'train_identity.csv'))\n",
    "test_identity = pd.read_csv(os.path.join(path,'test_identity.csv'))\n",
    "\n",
    "print('Data Readed!')\n",
    "print(f\"Shape of train_transaction: {train_transaction.shape}\\nShape of test_transaction: {test_transaction.shape}\\n\")\n",
    "print(f\"Shape of train_identity: {train_identity.shape}\\nShape of test_transaction: {test_identity.shape}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Merge Transaction and Identity Data üîó\n",
    "\n",
    "**What is a LEFT JOIN?**\n",
    "\n",
    "Think of it like this:\n",
    "- Transaction table = Main guest list (everyone is invited)\n",
    "- Identity table = VIP list (extra info for some guests)\n",
    "- LEFT JOIN = Keep ALL guests, add VIP info where available\n",
    "\n",
    "```\n",
    "Transaction Table          Identity Table\n",
    "+---------------+         +---------------+\n",
    "| TransactionID |         | TransactionID |\n",
    "| 100           |  LEFT   | 100 ‚Üí device  |   Result: 100 gets device info\n",
    "| 101           |  JOIN   | 103 ‚Üí device  |   Result: 101 gets NaN (no match)\n",
    "| 102           |    =    |               |   Result: 102 gets NaN\n",
    "| 103           |         |               |   Result: 103 gets device info\n",
    "+---------------+         +---------------+\n",
    "```\n",
    "\n",
    "**Why LEFT join instead of INNER?**\n",
    "- INNER would drop transactions without identity data (~76% of data lost!)\n",
    "- LEFT keeps all transactions, model can learn from missing identity patterns too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:28.889916Z",
     "iopub.status.busy": "2026-01-25T15:40:28.889412Z",
     "iopub.status.idle": "2026-01-25T15:40:30.664217Z",
     "shell.execute_reply": "2026-01-25T15:40:30.663575Z",
     "shell.execute_reply.started": "2026-01-25T15:40:28.889891Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train_df: (590540, 434)\n",
      "Shape of Test_df: (506691, 433)\n",
      "Merged\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------> 1\n",
    "\n",
    "\n",
    "def merge_transaction_identity(train_transaction,test_transaction,train_identity,test_identity) -> tuple:\n",
    "    \"This function merges Transaction and indentity data using common TransactionID column as left join\"\n",
    "\n",
    "    Train_df = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "    Test_df = test_transaction.merge(test_identity, on='TransactionID', how='left')\n",
    "    \n",
    "    print(f'Shape of Train_df: {Train_df.shape}\\nShape of Test_df: {Test_df.shape}')\n",
    "    print(\"Merged\")\n",
    "    \n",
    "    \n",
    "    #Free memory\n",
    "    \n",
    "    ## remove these vriables names from reference list\n",
    "    del train_transaction,train_identity, test_transaction,test_identity\n",
    "    return Train_df, Test_df\n",
    "\n",
    "\n",
    "Train_df, Test_df = merge_transaction_identity(train_transaction,test_transaction,train_identity,test_identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploratory Data Analysis (EDA) üîç\n",
    "\n",
    "**What is EDA?**\n",
    "EDA is like being a detective - we explore the data to understand patterns, find problems, and get insights before building a model.\n",
    "\n",
    "**What we're looking for:**\n",
    "1. **Class imbalance** - How many fraud vs non-fraud? (Important for choosing metrics)\n",
    "2. **Feature distributions** - What do the numbers look like?\n",
    "3. **Fraud patterns** - Which cards/emails/devices have more fraud?\n",
    "4. **Missing values** - Where is data missing and why?\n",
    "\n",
    "**First check: Target Variable Distribution**\n",
    "\n",
    "This pie chart shows us that fraud is RARE (~3.5%). This is called **class imbalance** - it's a major challenge because:\n",
    "- A dumb model saying \"not fraud\" for everything is 96.5% accurate!\n",
    "- We need smarter metrics like ROC-AUC that aren't fooled by this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:30.665371Z",
     "iopub.status.busy": "2026-01-25T15:40:30.665081Z",
     "iopub.status.idle": "2026-01-25T15:40:30.875324Z",
     "shell.execute_reply": "2026-01-25T15:40:30.874592Z",
     "shell.execute_reply.started": "2026-01-25T15:40:30.665349Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isFraud\n",
      "0    569877\n",
      "1     20663\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# target imbalance\n",
    "\n",
    "vc = Train_df['isFraud'].value_counts()\n",
    "print(vc)\n",
    "\n",
    "colors = sns.color_palette(\"pastel\")\n",
    "vc.plot(kind='pie', autopct='%1.2f%%', labels=['Not Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:30.876541Z",
     "iopub.status.busy": "2026-01-25T15:40:30.876260Z",
     "iopub.status.idle": "2026-01-25T15:40:30.947301Z",
     "shell.execute_reply": "2026-01-25T15:40:30.946492Z",
     "shell.execute_reply.started": "2026-01-25T15:40:30.876509Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>P_emaildomain</th>\n",
       "      <th>R_emaildomain</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>D10</th>\n",
       "      <th>D11</th>\n",
       "      <th>D12</th>\n",
       "      <th>D13</th>\n",
       "      <th>D14</th>\n",
       "      <th>D15</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "      <th>id_01</th>\n",
       "      <th>id_02</th>\n",
       "      <th>id_03</th>\n",
       "      <th>id_04</th>\n",
       "      <th>id_05</th>\n",
       "      <th>id_06</th>\n",
       "      <th>id_07</th>\n",
       "      <th>id_08</th>\n",
       "      <th>id_09</th>\n",
       "      <th>id_10</th>\n",
       "      <th>id_11</th>\n",
       "      <th>id_12</th>\n",
       "      <th>id_13</th>\n",
       "      <th>id_14</th>\n",
       "      <th>id_15</th>\n",
       "      <th>id_16</th>\n",
       "      <th>id_17</th>\n",
       "      <th>id_18</th>\n",
       "      <th>id_19</th>\n",
       "      <th>id_20</th>\n",
       "      <th>id_21</th>\n",
       "      <th>id_22</th>\n",
       "      <th>id_23</th>\n",
       "      <th>id_24</th>\n",
       "      <th>id_25</th>\n",
       "      <th>id_26</th>\n",
       "      <th>id_27</th>\n",
       "      <th>id_28</th>\n",
       "      <th>id_29</th>\n",
       "      <th>id_30</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>M2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>325.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>330.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>outlook.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>M0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>476.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>420.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70787.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>166.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>542.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>Android 7.0</td>\n",
       "      <td>samsung browser 6.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2220x1080</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5   card6  addr1  addr2  dist1  dist2  \\\n",
       "0    NaN  150.0    discover  142.0  credit  315.0   87.0   19.0    NaN   \n",
       "1  404.0  150.0  mastercard  102.0  credit  325.0   87.0    NaN    NaN   \n",
       "2  490.0  150.0        visa  166.0   debit  330.0   87.0  287.0    NaN   \n",
       "3  567.0  150.0  mastercard  117.0   debit  476.0   87.0    NaN    NaN   \n",
       "4  514.0  150.0  mastercard  102.0  credit  420.0   87.0    NaN    NaN   \n",
       "\n",
       "  P_emaildomain R_emaildomain   C1   C2   C3   C4   C5   C6   C7   C8   C9  \\\n",
       "0           NaN           NaN  1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "1     gmail.com           NaN  1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "2   outlook.com           NaN  1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "3     yahoo.com           NaN  2.0  5.0  0.0  0.0  0.0  4.0  0.0  0.0  1.0   \n",
       "4     gmail.com           NaN  1.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "\n",
       "   C10  C11  C12   C13  C14     D1     D2    D3    D4   D5  D6  D7  D8  D9  \\\n",
       "0  0.0  2.0  0.0   1.0  1.0   14.0    NaN  13.0   NaN  NaN NaN NaN NaN NaN   \n",
       "1  0.0  1.0  0.0   1.0  1.0    0.0    NaN   NaN   0.0  NaN NaN NaN NaN NaN   \n",
       "2  0.0  1.0  0.0   1.0  1.0    0.0    NaN   NaN   0.0  NaN NaN NaN NaN NaN   \n",
       "3  0.0  1.0  0.0  25.0  1.0  112.0  112.0   0.0  94.0  0.0 NaN NaN NaN NaN   \n",
       "4  1.0  1.0  0.0   1.0  1.0    0.0    NaN   NaN   NaN  NaN NaN NaN NaN NaN   \n",
       "\n",
       "    D10    D11  D12  D13  D14    D15   M1   M2   M3   M4  ... V330 V331 V332  \\\n",
       "0  13.0   13.0  NaN  NaN  NaN    0.0    T    T    T   M2  ...  NaN  NaN  NaN   \n",
       "1   0.0    NaN  NaN  NaN  NaN    0.0  NaN  NaN  NaN   M0  ...  NaN  NaN  NaN   \n",
       "2   0.0  315.0  NaN  NaN  NaN  315.0    T    T    T   M0  ...  NaN  NaN  NaN   \n",
       "3  84.0    NaN  NaN  NaN  NaN  111.0  NaN  NaN  NaN   M0  ...  NaN  NaN  NaN   \n",
       "4   NaN    NaN  NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  ...  0.0  0.0  0.0   \n",
       "\n",
       "  V333 V334  V335  V336  V337  V338  V339  id_01    id_02  id_03  id_04  \\\n",
       "0  NaN  NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN    NaN   \n",
       "1  NaN  NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN    NaN   \n",
       "2  NaN  NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN    NaN   \n",
       "3  NaN  NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN    NaN   \n",
       "4  0.0  0.0   0.0   0.0   0.0   0.0   0.0    0.0  70787.0    NaN    NaN   \n",
       "\n",
       "   id_05  id_06  id_07  id_08  id_09  id_10  id_11     id_12  id_13  id_14  \\\n",
       "0    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN   \n",
       "1    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN   \n",
       "2    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN   \n",
       "3    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN   \n",
       "4    NaN    NaN    NaN    NaN    NaN    NaN  100.0  NotFound    NaN -480.0   \n",
       "\n",
       "   id_15     id_16  id_17  id_18  id_19  id_20  id_21  id_22  id_23  id_24  \\\n",
       "0    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4    New  NotFound  166.0    NaN  542.0  144.0    NaN    NaN    NaN    NaN   \n",
       "\n",
       "   id_25  id_26  id_27  id_28     id_29        id_30                id_31  \\\n",
       "0    NaN    NaN    NaN    NaN       NaN          NaN                  NaN   \n",
       "1    NaN    NaN    NaN    NaN       NaN          NaN                  NaN   \n",
       "2    NaN    NaN    NaN    NaN       NaN          NaN                  NaN   \n",
       "3    NaN    NaN    NaN    NaN       NaN          NaN                  NaN   \n",
       "4    NaN    NaN    NaN    New  NotFound  Android 7.0  samsung browser 6.2   \n",
       "\n",
       "   id_32      id_33           id_34  id_35  id_36  id_37  id_38  DeviceType  \\\n",
       "0    NaN        NaN             NaN    NaN    NaN    NaN    NaN         NaN   \n",
       "1    NaN        NaN             NaN    NaN    NaN    NaN    NaN         NaN   \n",
       "2    NaN        NaN             NaN    NaN    NaN    NaN    NaN         NaN   \n",
       "3    NaN        NaN             NaN    NaN    NaN    NaN    NaN         NaN   \n",
       "4   32.0  2220x1080  match_status:2      T      F      T      T      mobile   \n",
       "\n",
       "                      DeviceInfo  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4  SAMSUNG SM-G892A Build/NRD90M  \n",
       "\n",
       "[5 rows x 434 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:30.948671Z",
     "iopub.status.busy": "2026-01-25T15:40:30.948310Z",
     "iopub.status.idle": "2026-01-25T15:40:30.953187Z",
     "shell.execute_reply": "2026-01-25T15:40:30.952576Z",
     "shell.execute_reply.started": "2026-01-25T15:40:30.948642Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027499999999999858"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(86499/3600)%24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:30.954271Z",
     "iopub.status.busy": "2026-01-25T15:40:30.954062Z",
     "iopub.status.idle": "2026-01-25T15:40:31.251304Z",
     "shell.execute_reply": "2026-01-25T15:40:31.250667Z",
     "shell.execute_reply.started": "2026-01-25T15:40:30.954252Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Transaction Amount Stats (Fraud vs Normal) ---\n",
      "            count        mean         std    min     25%   50%    75%  \\\n",
      "isFraud                                                                 \n",
      "0        569877.0  134.511665  239.395078  0.251  43.970  68.5  120.0   \n",
      "1         20663.0  149.244779  232.212163  0.292  35.044  75.0  161.0   \n",
      "\n",
      "               max  \n",
      "isFraud             \n",
      "0        31937.391  \n",
      "1         5191.000  \n",
      "\n",
      "||||---->\n",
      "\n",
      "--- Fraud Rate by Card Network & Type --- count = total volume , sum= frauds\n",
      "                                      mean   count   sum\n",
      "card4            card6                                  \n",
      "visa             debit            0.025476  301023  7669\n",
      "                 credit           0.068122   83732  5704\n",
      "mastercard       credit           0.069152   50772  3511\n",
      "                 debit            0.021566  138415  2985\n",
      "discover         credit           0.079315    6304   500\n",
      "american express credit           0.028624    8175   234\n",
      "discover         debit            0.040346     347    14\n",
      "american express debit            0.034722     144     5\n",
      "                 charge card      0.000000       3     0\n",
      "visa             charge card      0.000000      12     0\n",
      "mastercard       debit or credit  0.000000      30     0\n",
      "\n",
      "||||---->\n",
      "\n",
      "--- Top Risky Email Domains (by Fraud sum) ---\n",
      "                   mean   count   sum\n",
      "P_emaildomain                        \n",
      "gmail.com      0.043542  228355  9943\n",
      "hotmail.com    0.052950   45250  2396\n",
      "yahoo.com      0.022757  100934  2297\n",
      "anonymous.com  0.023217   36998   859\n",
      "aol.com        0.021811   28289   617\n",
      "outlook.com    0.094584    5096   482\n",
      "comcast.net    0.031187    7888   246\n",
      "icloud.com     0.031434    6267   197\n",
      "mail.com       0.189624     559   106\n",
      "msn.com        0.021994    4092    90\n",
      "\n",
      "||||---->\n",
      "\n",
      "--- Top Risky Device & OS Combinations ---\n",
      "                                      mean  count  sum\n",
      "id_30      id_31                                      \n",
      "Windows 7  chrome 63.0            0.049455   3579  177\n",
      "Windows 10 chrome 63.0            0.026451   5822  154\n",
      "iOS 11.2.5 mobile safari generic  0.126866   1072  136\n",
      "iOS 11.2.1 mobile safari 11.0     0.038718   2996  116\n",
      "iOS 11.1.2 mobile safari 11.0     0.034754   3050  106\n",
      "iOS 11.2.6 mobile safari generic  0.058863   1495   88\n",
      "iOS 11.2.2 mobile safari generic  0.174888    446   78\n",
      "iOS 11.3.0 mobile safari 11.0     0.062772   1147   72\n",
      "iOS 10.3.3 mobile safari 10.0     0.059524   1176   70\n",
      "iOS 11.2.1 mobile safari generic  0.094395    678   64\n",
      "\n",
      "||||---->\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Transaction Amount Analysis\n",
    "\n",
    "print(\"--- Transaction Amount Stats (Fraud vs Normal) ---\")\n",
    "print(Train_df.groupby('isFraud')['TransactionAmt'].describe())\n",
    "print('\\n||||---->\\n')\n",
    "\n",
    "# 2. Card Type Analysis\n",
    "# Grouping by Card Type first to see which specific combo is risky.\n",
    "# 'mean' = Risk Percentage, 'count' = Total Volume\n",
    "print(\"--- Fraud Rate by Card Network & Type --- count = total volume , sum= frauds\")\n",
    "card_stats = Train_df.groupby(['card4', 'card6'])['isFraud'].agg(['mean', 'count', 'sum'])\n",
    "# Sorting by 'sum' shows where the MOST fraud happens.\n",
    "# Sorting by 'mean' would show the HIGHEST RISK cards.\n",
    "print(card_stats.sort_values(by='sum', ascending=False))\n",
    "print('\\n||||---->\\n')\n",
    "\n",
    "\n",
    "# 3. Email Domain Analysis\n",
    "print(\"--- Top Risky Email Domains (by Fraud sum) ---\")\n",
    "email_stats = Train_df.groupby('P_emaildomain')['isFraud'].agg(['mean', 'count', 'sum'])\n",
    "print(email_stats.sort_values(by='sum', ascending=False).head(10))\n",
    "print('\\n||||---->\\n')\n",
    "\n",
    "\n",
    "# 4. Device & OS Analysis\n",
    "# Grouping by both to see the specific environment (e.g., Mobile Safari vs Desktop Chrome)\n",
    "print(\"--- Top Risky Device & OS Combinations ---\")\n",
    "device_stats = Train_df.groupby(['id_30', 'id_31'])['isFraud'].agg(['mean', 'count', 'sum'])\n",
    "print(device_stats.sort_values(by='sum', ascending=False).head(10))\n",
    "print('\\n||||---->\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness Checking üìä\n",
    "\n",
    "**What is skewness?**\n",
    "Skewness measures how \"lopsided\" a distribution is:\n",
    "- Skewness = 0 ‚Üí Symmetric (like a bell curve)\n",
    "- Skewness > 0 ‚Üí Right-tailed (most values small, few very large)\n",
    "- Skewness < 0 ‚Üí Left-tailed (most values large, few very small)\n",
    "\n",
    "**Example with TransactionAmt:**\n",
    "Most transactions are small ($50-$100), but some are very large ($5000+). This creates a right-skewed distribution.\n",
    "\n",
    "**Why check skewness?**\n",
    "- For tree-based models (LightGBM, XGBoost) ‚Üí Skewness is NOT a problem! Trees split on values, not distributions.\n",
    "- For linear models (Logistic Regression) ‚Üí High skewness CAN hurt performance.\n",
    "\n",
    "Since we'll use LightGBM (a tree-based model), we don't need to worry about skewness, but it's good practice to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:31.252304Z",
     "iopub.status.busy": "2026-01-25T15:40:31.252092Z",
     "iopub.status.idle": "2026-01-25T15:40:33.870704Z",
     "shell.execute_reply": "2026-01-25T15:40:33.870040Z",
     "shell.execute_reply.started": "2026-01-25T15:40:31.252276Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID     3.024053e-16\n",
       "isFraud           5.061223e+00\n",
       "TransactionDT     1.311547e-01\n",
       "TransactionAmt    1.437449e+01\n",
       "card1             4.092898e-02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewed_cols = Train_df.skew(numeric_only=True).abs()\n",
    "skewed_cols.head()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature Engineering üõ†Ô∏è\n",
    "\n",
    "**What is Feature Engineering?**\n",
    "Creating NEW columns from existing data that help the model understand patterns better.\n",
    "\n",
    "**Why is it important?**\n",
    "Raw data often doesn't clearly show fraud patterns. For example:\n",
    "- `TransactionAmt = 100` tells us nothing\n",
    "- `TransactionAmt = 100 AND user's average is $20` ‚Üí 5x higher than normal! üö®\n",
    "\n",
    "**Our feature engineering categories:**\n",
    "1. **Memory Reduction** - Make data smaller to process faster\n",
    "2. **Transaction Amount Features** - Patterns in how much is spent\n",
    "3. **Time Features** - When transactions happen\n",
    "4. **Card Features** - Card usage patterns\n",
    "5. **Email Features** - Email domain patterns\n",
    "6. **Device Features** - Device/browser patterns\n",
    "7. **Address Features** - Location patterns\n",
    "8. **V-column aggregations** - Summarize anonymous features\n",
    "9. **C/D column features** - Counting and time delta patterns\n",
    "10. **ID features** - Identity verification patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Memory Reduction üíæ\n",
    "\n",
    "**The Problem:**\n",
    "Our DataFrame uses 1,955 MB of memory. That's almost 2 GB just for training data!\n",
    "\n",
    "**Why so much?**\n",
    "By default, pandas uses:\n",
    "- `int64` for integers (8 bytes per value)\n",
    "- `float64` for decimals (8 bytes per value)\n",
    "\n",
    "But most of our values don't need that precision!\n",
    "\n",
    "**The Solution:**\n",
    "Look at each column's min and max values, then choose the smallest data type:\n",
    "\n",
    "| Original Type | Min Value | Max Value | New Type | Memory Saved |\n",
    "|--------------|-----------|-----------|----------|--------------|\n",
    "| int64 | -128 | 127 | int8 | 87.5% |\n",
    "| int64 | -32,768 | 32,767 | int16 | 75% |\n",
    "| float64 | Any small range | | float32 | 50% |\n",
    "\n",
    "**Example:**\n",
    "- `isFraud` is 0 or 1 ‚Üí Only needs `int8` (1 byte) not `int64` (8 bytes)\n",
    "- `card1` ranges 1-18,000 ‚Üí Only needs `int16` (2 bytes) not `int64` (8 bytes)\n",
    "\n",
    "**Result:** Memory reduced from 1,955 MB ‚Üí 1,044 MB (46.6% savings!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:33.873382Z",
     "iopub.status.busy": "2026-01-25T15:40:33.873119Z",
     "iopub.status.idle": "2026-01-25T15:40:33.878240Z",
     "shell.execute_reply": "2026-01-25T15:40:33.877549Z",
     "shell.execute_reply.started": "2026-01-25T15:40:33.873358Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32767"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.iinfo(np.int16).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:33.879551Z",
     "iopub.status.busy": "2026-01-25T15:40:33.879272Z",
     "iopub.status.idle": "2026-01-25T15:40:36.642564Z",
     "shell.execute_reply": "2026-01-25T15:40:36.641750Z",
     "shell.execute_reply.started": "2026-01-25T15:40:33.879529Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 1955.37 MB -> 1044.70 MB (46.6% reduction)\n",
      "Memory usage: 1673.87 MB -> 895.89 MB (46.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "def reduce_memory(df, verbose=True):\n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                # Skip float16 due to compatibility issues, use float32 as minimum\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f'Memory usage: {start_memory:.2f} MB -> {end_mem:.2f} MB ({100 * (start_memory - end_mem) / start_memory:.1f}% reduction)')\n",
    "    return df\n",
    "\n",
    "                    \n",
    "Train_df = reduce_memory(Train_df, True)\n",
    "Test_df = reduce_memory(Test_df, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.2 Transaction Amount Features**\n",
    "\n",
    "1. Log Transform: Normalizes the skewed distribution of money.\n",
    "2. Decimal extraction: Fraudsters might use automated bots resulting in specific decimal patterns, or round numbers (no cents).\n",
    "\n",
    "3. Micro Amount(testing behaviour) : Fraudsters test the account by spending small amounts\n",
    "\n",
    "\n",
    "4. Sudden spike in amount\n",
    "## Simple example (IEEE-CIS style)\n",
    "\n",
    "### Raw data (unsorted)\n",
    "\n",
    "| card_id | TransactionDT | TransactionAmt |\n",
    "| ------- | ------------- | -------------- |\n",
    "| A       | 200           | 100            |\n",
    "| A       | 100           | 5              |\n",
    "| A       | 300           | 800            |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3AÔ∏è‚É£ Sort correctly\n",
    "\n",
    "```python\n",
    "df = df.sort_values(['card_id', 'TransactionDT'])\n",
    "```\n",
    "\n",
    "After sorting:\n",
    "\n",
    "| card_id | TransactionDT | TransactionAmt |\n",
    "| ------- | ------------- | -------------- |\n",
    "| A       | 100           | 5              |\n",
    "| A       | 200           | 100            |\n",
    "| A       | 300           | 800            |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3BÔ∏è‚É£ Create **previous amount**\n",
    "\n",
    "```python\n",
    "df['prev_amount'] = df.groupby('card_id')['TransactionAmt'].shift(1)\n",
    "```\n",
    "\n",
    "Result:\n",
    "\n",
    "| card_id | TransactionDT | TransactionAmt | prev_amount |\n",
    "| ------- | ------------- | -------------- | ----------- |\n",
    "| A       | 100           | 5              | NaN         |\n",
    "| A       | 200           | 100            | 5           |\n",
    "| A       | 300           | 800            | 100         |\n",
    "\n",
    "---\n",
    "\n",
    "## Why this matters for fraud detection\n",
    "\n",
    "Fraudsters often do:\n",
    "\n",
    "```\n",
    "‚Çπ5  ‚Üí ‚Çπ100 ‚Üí ‚Çπ800\n",
    "(test) ‚Üí (check) ‚Üí (drain)\n",
    "```\n",
    "\n",
    "This feature lets your model **see the jump**.\n",
    "\n",
    "---\n",
    "\n",
    "## Why `shift(1)` is the key\n",
    "\n",
    "`shift(1)` means:\n",
    "\n",
    "* Take the **previous row after sorting**\n",
    "* Push it **down by one**\n",
    "* So **only past info is used**\n",
    "\n",
    "No future leakage üö´\n",
    "\n",
    "---\n",
    "\n",
    "## How the model uses it\n",
    "\n",
    "You don‚Äôt use `prev_amount` directly ‚Äî you compare it:\n",
    "\n",
    "```python\n",
    "df['amount_jump_ratio'] = df['TransactionAmt'] / (df['prev_amount'] + 1)\n",
    "```\n",
    "\n",
    "| Current | Previous | Ratio |\n",
    "| ------- | -------- | ----- |\n",
    "| 100     | 5        | 20 üö® |\n",
    "| 800     | 100      | 8 üö®  |\n",
    "| 120     | 100      | 1.2 ‚úÖ |\n",
    "\n",
    "---\n",
    "\n",
    "## Edge case (first transaction)\n",
    "\n",
    "* First transaction per card ‚Üí `prev_amount = NaN`\n",
    "* This is **normal**\n",
    "* You can fill with:\n",
    "\n",
    "```python\n",
    "df['prev_amount'] = df['prev_amount'].fillna(df['TransactionAmt'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## TL;DR\n",
    "\n",
    "* **Previous amount** = last transaction amount of the **same card**\n",
    "* Sorting by `card_id + TransactionDT` is mandatory\n",
    "* `shift(1)` guarantees **no data leakage**\n",
    "* It helps detect **sudden jumps ‚Üí fraud**\n",
    "\n",
    "\n",
    "5. Rolling median\n",
    "## First: what‚Äôs the problem with ‚Äúprevious amount‚Äù?\n",
    "\n",
    "Using only the **last transaction** can be noisy.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "‚Çπ5 ‚Üí ‚Çπ500 ‚Üí ‚Çπ10 ‚Üí ‚Çπ600\n",
    "```\n",
    "\n",
    "If you compare only to the last one:\n",
    "\n",
    "* ‚Çπ500 ‚Üí ‚Çπ10 looks like a **drop**\n",
    "* ‚Çπ10 ‚Üí ‚Çπ600 looks like a **huge spike**\n",
    "\n",
    "But **the user‚Äôs normal behavior** is actually around **‚Çπ500‚Äì‚Çπ600**.\n",
    "\n",
    "So the *previous amount alone can mislead*.\n",
    "\n",
    "---\n",
    "\n",
    "## What is ‚Äúrolling median‚Äù (in plain English)?\n",
    "\n",
    "üëâ **Rolling median = the ‚Äútypical‚Äù amount the card usually spends, based on the last few transactions.**\n",
    "\n",
    "Not the last one ‚Äî but the **recent pattern**.\n",
    "\n",
    "---\n",
    "\n",
    "## Simple analogy üß†\n",
    "\n",
    "Think of:\n",
    "\n",
    "* **Previous amount** ‚Üí ‚ÄúWhat did you spend last time?‚Äù\n",
    "* **Rolling median** ‚Üí ‚ÄúWhat do you usually spend?‚Äù\n",
    "\n",
    "Fraud is easier to catch when something is **far from usual**, not just far from last time.\n",
    "\n",
    "---\n",
    "\n",
    "## Example (last 5 transactions)\n",
    "\n",
    "| Transaction history          | Median   |\n",
    "| ---------------------------- | -------- |\n",
    "| ‚Çπ450, ‚Çπ500, ‚Çπ520, ‚Çπ480, ‚Çπ510 | **‚Çπ500** |\n",
    "\n",
    "Now:\n",
    "\n",
    "* New transaction = ‚Çπ4,000\n",
    "  ‚û° Compared to **‚Çπ500**, this is clearly suspicious üö®\n",
    "\n",
    "---\n",
    "\n",
    "## Why *median* and not *mean*?\n",
    "\n",
    "Because fraud itself creates **extreme values**.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "‚Çπ500, ‚Çπ520, ‚Çπ480, ‚Çπ450, ‚Çπ10,000\n",
    "```\n",
    "\n",
    "* Mean ‚âà **‚Çπ2,158** ‚ùå (polluted)\n",
    "* Median = **‚Çπ500** ‚úÖ (stable)\n",
    "\n",
    "Median ignores outliers ‚Äî perfect for fraud.\n",
    "\n",
    "---\n",
    "\n",
    "## What the feature means\n",
    "\n",
    "This line:\n",
    "\n",
    "```python\n",
    "amt_vs_rolling = current_amount / rolling_median_amount\n",
    "```\n",
    "\n",
    "Means:\n",
    "\n",
    "> ‚ÄúHow big is this transaction compared to what this card usually spends?‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## Why this feature is **very strong** in IEEE-CIS\n",
    "\n",
    "* Cards have **behavior patterns**\n",
    "* Fraud breaks behavior suddenly\n",
    "* Rolling median captures **normal behavior**\n",
    "* Ratio captures **sudden abnormality**\n",
    "\n",
    "That‚Äôs why it often beats ‚Äúprevious amount‚Äù.\n",
    "\n",
    "---\n",
    "\n",
    "## TL;DR (one sentence)\n",
    "\n",
    "**Rolling median = recent normal spending; fraud = sudden break from normal ‚Äî comparing them makes fraud obvious.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6. same amount repeated multiple times\n",
    "7. High amount compared to user‚Äôs normal behavior\n",
    "\n",
    "Fraud is contextual, not absolute.\n",
    "\n",
    "‚Çπ5,000 may be normal for one user, suspicious for another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:36.644261Z",
     "iopub.status.busy": "2026-01-25T15:40:36.643678Z",
     "iopub.status.idle": "2026-01-25T15:40:44.500650Z",
     "shell.execute_reply": "2026-01-25T15:40:44.499720Z",
     "shell.execute_reply.started": "2026-01-25T15:40:36.644236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_transaction_amount_features(df) -> pd.DataFrame:\n",
    "    \"\"\"Create features based on transaction amount\"\"\"\n",
    "    # Log transformation\n",
    "    df['TransactionAmt_log'] = np.log1p(df['TransactionAmt'])\n",
    "    \n",
    "    # Decimal part extraction: often fraudsters use round numbers\n",
    "    df['TransactionAmt_decimal'] = ((df['TransactionAmt'] - df['TransactionAmt'].astype(int)) * 1000).fillna(0).astype(int)\n",
    "    \n",
    "    # Is round\n",
    "    df['TransactionAmt_is_round'] = (df['TransactionAmt'] == df['TransactionAmt'].astype(int)).astype(int)\n",
    "    \n",
    "    # Amount bin: it can reduce noise by smoothing and other benefits too\n",
    "    df['TransactionAmt_bins'] = pd.cut(\n",
    "        df['TransactionAmt'].astype('float32'),\n",
    "        bins=[0, 50, 100, 200, 500, 1000, 5000, 10_000, np.inf],\n",
    "        labels=[0, 1, 2, 3, 4, 5, 6, 7]\n",
    "    ).astype(float)\n",
    "    \n",
    "    # Value in cents\n",
    "    df['TransactionAmt_cents'] = (df['TransactionAmt'] * 100 % 100).fillna(0).astype(int)\n",
    "    \n",
    "    # Is micro amount\n",
    "    df['TransactionAmt_is_micro'] = (df['TransactionAmt'] < 10).astype(int)\n",
    "    \n",
    "    # Sudden amount jump\n",
    "    card_cols = ['card1', 'card2', 'card3', 'card4', 'card5', 'card6']\n",
    "    df['card_id'] = df[card_cols].astype(str).agg('_'.join, axis=1)\n",
    "    \n",
    "    df = df.sort_values(['card_id', 'TransactionDT'])\n",
    "    df['prev_amount'] = (\n",
    "        df.groupby('card_id')['TransactionAmt']\n",
    "          .shift(1)\n",
    "    )\n",
    "    \n",
    "    df['prev_amount'] = df['prev_amount'].fillna(df['TransactionAmt'])\n",
    "    df['amount_jump_ratio'] = df['TransactionAmt'] / (df['prev_amount'] + 1)\n",
    "    \n",
    "    df['is_amount_spike'] = (df['amount_jump_ratio'] > 5).astype(int)\n",
    "    \n",
    "    # Rolling mean\n",
    "    df['rolling_median_amt'] = (\n",
    "        df.groupby('card_id')['TransactionAmt']\n",
    "          .rolling(5, min_periods=1)\n",
    "          .median()\n",
    "          .shift(1)\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df['rolling_median_amt'] = df['rolling_median_amt'].fillna(df['TransactionAmt'])\n",
    "    df['amt_vs_rolling'] = df['TransactionAmt'] / (df['rolling_median_amt'] + 1)\n",
    "    \n",
    "    # Same amount repeated multiple times\n",
    "    df['amt_repeat_count'] = (\n",
    "        df.groupby(['card_id', 'TransactionAmt'])['TransactionAmt']\n",
    "          .transform('count')\n",
    "    )\n",
    "    \n",
    "    # High amount compared to user's normal behavior (if user_id column exists)\n",
    "    if 'user_id' in df.columns:\n",
    "        user_mean = df.groupby('user_id')['TransactionAmt'].transform('mean')\n",
    "        user_std = df.groupby('user_id')['TransactionAmt'].transform('std')\n",
    "        df['amount_zscore'] = (df['TransactionAmt'] - user_mean) / (user_std + 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "Train_df = create_transaction_amount_features(Train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Time Features ‚è∞\n",
    "\n",
    "**Key insight:** Fraudsters work \"off-hours\" when victims are asleep!\n",
    "\n",
    "**Why time matters:**\n",
    "- Legitimate users shop during waking hours\n",
    "- Fraud often happens at night (2am-5am) when no one notices\n",
    "- Business transactions happen 9am-5pm weekdays\n",
    "\n",
    "**Features we create:**\n",
    "\n",
    "| Feature | What it captures |\n",
    "|---------|------------------|\n",
    "| `Transaction_hour` | Hour of day (0-23) |\n",
    "| `Transaction_time_of_day` | 0=night, 1=morning, 2=afternoon, 3=evening |\n",
    "| `Transaction_is_night` | 12am-6am flag (high fraud risk) |\n",
    "| `Transaction_is_business_hour` | 9am-5pm flag (normal behavior) |\n",
    "| `Transaction_time_gap` | Seconds since last transaction by same card |\n",
    "| `Transaction_cnt_1hr` | Count of transactions in last hour (velocity) |\n",
    "\n",
    "**Cyclic encoding - why sin/cos?**\n",
    "Hours are circular: 11pm (23) is close to 1am (1), but numerically they're far (23 vs 1).\n",
    "\n",
    "Using sin/cos:\n",
    "- `hour_sin = sin(2œÄ √ó hour / 24)`\n",
    "- `hour_cos = cos(2œÄ √ó hour / 24)`\n",
    "\n",
    "This makes 23:00 and 01:00 appear close to the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:44.502524Z",
     "iopub.status.busy": "2026-01-25T15:40:44.501943Z",
     "iopub.status.idle": "2026-01-25T15:40:45.355358Z",
     "shell.execute_reply": "2026-01-25T15:40:45.354770Z",
     "shell.execute_reply.started": "2026-01-25T15:40:44.502498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create time-based features from TransactionDT (seconds since reference time)\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Basic time decomposition\n",
    "    # -------------------------\n",
    "\n",
    "    # Hour of day (0‚Äì23) derived from seconds\n",
    "    df['Transaction_hour'] = (df['TransactionDT'] // 3600) % 24\n",
    "\n",
    "    # Seconds within a day (cyclic behavior)\n",
    "    df['Transaction_sec_in_day'] = df['TransactionDT'] % 86400\n",
    "\n",
    "    # Time of day buckets\n",
    "    # 0 = night, 1 = morning, 2 = afternoon, 3 = evening\n",
    "    df['Transaction_time_of_day'] = pd.cut(\n",
    "        df['Transaction_hour'],\n",
    "        bins=[-1, 6, 12, 18, 24],\n",
    "        labels=[0, 1, 2, 3]\n",
    "    ).astype(int)\n",
    "\n",
    "    # -------------------------\n",
    "    # Binary behavior flags\n",
    "    # -------------------------\n",
    "\n",
    "    # Night transactions (fraud often spikes at night)\n",
    "    df['Transaction_is_night'] = (\n",
    "        (df['Transaction_hour'] >= 0) & (df['Transaction_hour'] < 6)\n",
    "    ).astype(int)\n",
    "\n",
    "    # Business hours (normal human activity)\n",
    "    df['Transaction_is_business_hour'] = (\n",
    "        (df['Transaction_hour'] >= 9) & (df['Transaction_hour'] <= 17)\n",
    "    ).astype(int)\n",
    "\n",
    "    # -------------------------\n",
    "    # Sequential time features\n",
    "    # -------------------------\n",
    "\n",
    "    # Time gap from previous transaction for the same card\n",
    "    # (detects bursts / bot activity)\n",
    "    df['Transaction_time_gap'] = (\n",
    "        df.groupby('card_id')['TransactionDT']\n",
    "          .diff()\n",
    "    )\n",
    "\n",
    "    # Fill first transaction gap with large value (no previous txn)\n",
    "    df['Transaction_time_gap'] = df['Transaction_time_gap'].fillna(999999)\n",
    "\n",
    "    # -------------------------\n",
    "    # Velocity features\n",
    "    # -------------------------\n",
    "\n",
    "    # Number of transactions in last 1 hour per card\n",
    "    df['Transaction_cnt_1hr'] = (\n",
    "        df.groupby('card_id')['TransactionDT']\n",
    "          .rolling(3600)\n",
    "          .count()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # Cyclic encoding (tree + linear friendly)\n",
    "    # -------------------------\n",
    "\n",
    "    # Sine/Cosine encoding of hour (captures cyclic nature)\n",
    "    df['Transaction_hour_sin'] = np.sin(2 * np.pi * df['Transaction_hour'] / 24)\n",
    "    df['Transaction_hour_cos'] = np.cos(2 * np.pi * df['Transaction_hour'] / 24)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "Train_df = create_time_features(Train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Card Features üí≥\n",
    "\n",
    "**What the card columns mean:**\n",
    "- `card1` ‚Üí Hashed card number (identifies the card)\n",
    "- `card2` ‚Üí Issuer/bank information\n",
    "- `card3` ‚Üí Card currency (150 = USD)\n",
    "- `card4` ‚Üí Network (visa, mastercard, discover, amex)\n",
    "- `card5` ‚Üí Card category code\n",
    "- `card6` ‚Üí Card type (credit, debit, charge card)\n",
    "\n",
    "**Why combine card columns?**\n",
    "A single `card1` value might be used with different addresses. Combining them creates a unique \"user fingerprint\":\n",
    "\n",
    "```\n",
    "card_id = card1 + card2 + card3 + card4 + card5 + card6\n",
    "Example: \"13926_NaN_150.0_discover_142.0_credit\"\n",
    "```\n",
    "\n",
    "**Features we create:**\n",
    "\n",
    "| Feature | Purpose |\n",
    "|---------|---------|\n",
    "| `card_id` | Unique card fingerprint |\n",
    "| `card1_addr1` | Card + billing address (detect new locations) |\n",
    "| `card1_ProductCD` | Card + product type (unusual purchases) |\n",
    "| `card_id_count` | How many times card appears (high = suspicious) |\n",
    "| `card_add_count` | Transactions from same address (aggregated behavior) |\n",
    "\n",
    "**Why card + address combinations matter:**\n",
    "If a card normally used in New York suddenly appears in Mumbai ‚Üí üö® Suspicious!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:45.356515Z",
     "iopub.status.busy": "2026-01-25T15:40:45.356240Z",
     "iopub.status.idle": "2026-01-25T15:40:52.522230Z",
     "shell.execute_reply": "2026-01-25T15:40:52.521311Z",
     "shell.execute_reply.started": "2026-01-25T15:40:45.356489Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start creating card Features...\n",
      "Card features has been created successfully\n"
     ]
    }
   ],
   "source": [
    "def create_card_features(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"This func create card related features\"\n",
    "    print(\"Start creating card Features...\")\n",
    "\n",
    "    card_cols = ['card1', 'card2', 'card3', 'card4', 'card5', 'card6']\n",
    "    for i in card_cols:\n",
    "        if i in df.columns:\n",
    "            df[i]=df[i].fillna(-1).astype(str)\n",
    "    #since we already created card_id with combining all cards so we dont need to make smaller combination like card1_card2 etc  but we can combine address and card\n",
    "\n",
    "    df['card1_addrs1'] = df['card1']+ \"-\" + df['addr1'].fillna(0).astype(str)\n",
    "    df['card1_addrs2'] = df['card1']+ \"-\" + df['addr2'].fillna(0).astype(str)\n",
    "    df['card2_addrs1'] = df['card2']+ \"-\" + df['addr1'].fillna(0).astype(str)\n",
    "\n",
    "\n",
    "    #maybe fraudsters can buy specific products while doing frauds\n",
    "    df['card1_ProductCD'] = df[['card1','ProductCD']].ffill().astype(str).agg('_'.join, axis=1)\n",
    "    df['card2_ProductCD'] = df[['card2','ProductCD']].ffill().astype(str).agg('_'.join, axis=1)\n",
    "\n",
    "    #card uses frequency ---> not use agg('count'); but transform('count') becasue it will return one counted value for original one row\n",
    "    df['card_id_count'] = df.groupby('card_id')['TransactionID'].transform('count')\n",
    "\n",
    "    # card+ address frequency\n",
    "    df['card_add_count'] = df.groupby('addr1')['TransactionID'].transform('count')\n",
    "\n",
    "    print('Card features has been created successfully')    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "Train_df = create_card_features(Train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Email Features üìß\n",
    "\n",
    "**What the email columns mean:**\n",
    "- `P_emaildomain` ‚Üí Purchaser's email (person buying)\n",
    "- `R_emaildomain` ‚Üí Recipient's email (person receiving)\n",
    "\n",
    "**Key fraud patterns in emails:**\n",
    "1. **Unknown domains** - Rare/suspicious email providers\n",
    "2. **Domain mismatch** - Purchaser ‚â† Recipient (e.g., buying for \"someone else\")\n",
    "3. **Certain providers** - Some domains have higher fraud rates (e.g., mail.com: 19%!)\n",
    "\n",
    "**Features we create:**\n",
    "\n",
    "| Feature | What it detects |\n",
    "|---------|-----------------|\n",
    "| `P_email_vendor` | Provider: google, microsoft, yahoo, apple, other |\n",
    "| `email_domain_match` | P_email == R_email (1=match, 0=different) |\n",
    "| `email_presence` | both_present, only_P, only_R, both_missing |\n",
    "| `P_domain_count` | How common is this email domain? |\n",
    "| `P_domain_fraud_rate` | Historical fraud rate for this domain (target encoding) |\n",
    "\n",
    "**What is target encoding?**\n",
    "Replace email domain with its historical fraud rate. But we use K-Fold to avoid data leakage:\n",
    "\n",
    "```\n",
    "Training fold 1 ‚Üí Calculate fraud rate from folds 2-5\n",
    "Training fold 2 ‚Üí Calculate fraud rate from folds 1,3,4,5\n",
    "... and so on\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:52.523930Z",
     "iopub.status.busy": "2026-01-25T15:40:52.523335Z",
     "iopub.status.idle": "2026-01-25T15:40:56.777192Z",
     "shell.execute_reply": "2026-01-25T15:40:56.776342Z",
     "shell.execute_reply.started": "2026-01-25T15:40:52.523904Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tldextract\n",
      "  Downloading tldextract-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from tldextract) (3.11)\n",
      "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from tldextract) (2.32.5)\n",
      "Collecting requests-file>=1.4 (from tldextract)\n",
      "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract) (3.20.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.1.0->tldextract) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.1.0->tldextract) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.1.0->tldextract) (2026.1.4)\n",
      "Downloading tldextract-5.3.1-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
      "Installing collected packages: requests-file, tldextract\n",
      "Successfully installed requests-file-3.0.1 tldextract-5.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tldextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:40:56.779100Z",
     "iopub.status.busy": "2026-01-25T15:40:56.778807Z",
     "iopub.status.idle": "2026-01-25T15:41:14.403948Z",
     "shell.execute_reply": "2026-01-25T15:41:14.403249Z",
     "shell.execute_reply.started": "2026-01-25T15:40:56.779071Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install tldextract\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# try to use tldextract; otherwise provide a fallback extractor\n",
    "try:\n",
    "    import tldextract\n",
    "\n",
    "    def extract_domain_parts(domain):\n",
    "        # returns (subdomain, domain, suffix) similar to tldextract.extract\n",
    "        ext = tldextract.extract(domain)\n",
    "        return ext.subdomain, ext.domain, ext.suffix\n",
    "\n",
    "except Exception:\n",
    "    # lightweight fallback (not as complete as tldextract, but works for common cases)\n",
    "    def extract_domain_parts(domain):\n",
    "        \"\"\"\n",
    "        Very small fallback:\n",
    "         - treats 'co.uk', 'gov.uk', 'ac.uk' as double-suffix when seen\n",
    "         - returns (subdomain, domain, suffix)\n",
    "        \"\"\"\n",
    "        if not isinstance(domain, str) or domain in ('', 'missing', 'nan'):\n",
    "            return '', 'missing', ''\n",
    "        domain = domain.lower().strip()\n",
    "        parts = domain.split('.')\n",
    "        if len(parts) == 1:\n",
    "            return '', parts[0], ''\n",
    "        # handle common double-suffixes\n",
    "        double_suffixes = {'co.uk', 'gov.uk', 'ac.uk', 'co.jp', 'com.au', 'net.au'}\n",
    "        last_two = '.'.join(parts[-2:])\n",
    "        if last_two in double_suffixes:\n",
    "            suffix = last_two\n",
    "            dom = parts[-3] if len(parts) >= 3 else parts[-2]\n",
    "            sub = '.'.join(parts[:-3]) if len(parts) > 3 else ''\n",
    "            return sub, dom, suffix\n",
    "        else:\n",
    "            suffix = parts[-1]\n",
    "            dom = parts[-2]\n",
    "            sub = '.'.join(parts[:-2]) if len(parts) > 2 else ''\n",
    "            return sub, dom, suffix\n",
    "\n",
    "def create_email_features(df, target_col='isFraud', n_splits=5):\n",
    "    df = df.copy()\n",
    "\n",
    "    # normalize & fill\n",
    "    for col in ['P_emaildomain', 'R_emaildomain']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('missing').astype(str).str.lower()\n",
    "        else:\n",
    "            df[col] = 'missing'  # ensures downstream code won't fail\n",
    "\n",
    "    # vendor map\n",
    "    vendor_map = {\n",
    "        'gmail': 'google',\n",
    "        'yahoo': 'yahoo',\n",
    "        'hotmail': 'microsoft',\n",
    "        'outlook': 'microsoft',\n",
    "        'live': 'microsoft',\n",
    "        'msn': 'microsoft',\n",
    "        'icloud': 'apple',\n",
    "        'aol': 'aol'\n",
    "    }\n",
    "\n",
    "    def get_vendor(domain):\n",
    "        _, dom, _ = extract_domain_parts(domain)\n",
    "        return vendor_map.get(dom, 'other')\n",
    "\n",
    "    def get_tld(domain):\n",
    "        _, _, suffix = extract_domain_parts(domain)\n",
    "        return suffix if suffix else 'missing'\n",
    "\n",
    "    # apply safely\n",
    "    df['P_email_vendor'] = df['P_emaildomain'].apply(get_vendor)\n",
    "    df['R_email_vendor'] = df['R_emaildomain'].apply(get_vendor)\n",
    "    df['P_email_tld'] = df['P_emaildomain'].apply(get_tld)\n",
    "    df['R_email_tld'] = df['R_emaildomain'].apply(get_tld)\n",
    "\n",
    "    # match and presence\n",
    "    df['email_domain_match'] = (df['P_emaildomain'] == df['R_emaildomain']).astype(int)\n",
    "    df['email_presence'] = np.select(\n",
    "        [\n",
    "            (df['P_emaildomain'] != 'missing') & (df['R_emaildomain'] != 'missing'),\n",
    "            (df['P_emaildomain'] != 'missing') & (df['R_emaildomain'] == 'missing'),\n",
    "            (df['P_emaildomain'] == 'missing') & (df['R_emaildomain'] != 'missing')\n",
    "        ],\n",
    "        ['both_present', 'only_P', 'only_R'],\n",
    "        default='both_missing'\n",
    "    )\n",
    "\n",
    "    # domain frequency: ensure TransactionID exists (if not, use index)\n",
    "    id_col = 'TransactionID' if 'TransactionID' in df.columns else None\n",
    "    if id_col:\n",
    "        df['P_domain_count'] = df.groupby('P_emaildomain')[id_col].transform('count')\n",
    "        df['R_domain_count'] = df.groupby('R_emaildomain')[id_col].transform('count')\n",
    "    else:\n",
    "        df['P_domain_count'] = df.groupby('P_emaildomain')['P_emaildomain'].transform('count')\n",
    "        df['R_domain_count'] = df.groupby('R_emaildomain')['R_emaildomain'].transform('count')\n",
    "\n",
    "    # K-Fold target encoding (only for P_emaildomain). Works even if target missing -> all NaNs replaced by global mean\n",
    "    df['P_domain_fraud_rate'] = np.nan\n",
    "    if target_col in df.columns:\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        for train_idx, val_idx in kf.split(df):\n",
    "            train_df = df.iloc[train_idx]\n",
    "            val_df = df.iloc[val_idx]\n",
    "            mapping = train_df.groupby('P_emaildomain')[target_col].mean()\n",
    "            df.loc[val_idx, 'P_domain_fraud_rate'] = val_df['P_emaildomain'].map(mapping)\n",
    "        global_mean = df[target_col].mean()\n",
    "        df['P_domain_fraud_rate'] = df['P_domain_fraud_rate'].fillna(global_mean)\n",
    "    else:\n",
    "        df['P_domain_fraud_rate'] = 0.0\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "Train_df = create_email_features(Train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Device Features üì±üíª\n",
    "\n",
    "**Why devices matter for fraud:**\n",
    "- Fraud farms use specific device/browser combinations\n",
    "- Emulators and bots have unusual screen resolutions\n",
    "- Mobile vs Desktop have different fraud patterns\n",
    "\n",
    "**Device columns explained:**\n",
    "- `DeviceType` ‚Üí mobile or desktop\n",
    "- `DeviceInfo` ‚Üí Full device string (e.g., \"SAMSUNG SM-G892A Build/NRD90M\")\n",
    "- `id_30` ‚Üí Operating system (e.g., \"Android 7.0\", \"iOS 11.2\")\n",
    "- `id_31` ‚Üí Browser (e.g., \"chrome 63.0\", \"mobile safari 11.0\")\n",
    "- `id_33` ‚Üí Screen resolution (e.g., \"2220x1080\")\n",
    "\n",
    "**Features we create:**\n",
    "\n",
    "| Feature | What it captures |\n",
    "|---------|------------------|\n",
    "| `DeviceType_is_mobile` | Mobile device flag |\n",
    "| `Device_brand` | Extracted brand (Samsung, Apple, etc.) |\n",
    "| `DeviceInfo_length` | Long strange names = suspicious |\n",
    "| `Browser_is_chrome/safari/etc` | Specific browser flags |\n",
    "| `OS_is_Windows/Mac/iOS/Android` | Operating system flags |\n",
    "| `Screen_width/height/area` | Resolution (unusual = emulator) |\n",
    "| `Screen_aspect_ratio` | Width √∑ Height (weird ratios = bots) |\n",
    "\n",
    "**High fraud combinations found:**\n",
    "- iOS 11.2.5 + mobile safari generic ‚Üí 12.7% fraud rate\n",
    "- iOS 11.2.2 + mobile safari generic ‚Üí 17.5% fraud rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:41:14.405294Z",
     "iopub.status.busy": "2026-01-25T15:41:14.405011Z",
     "iopub.status.idle": "2026-01-25T15:41:38.696203Z",
     "shell.execute_reply": "2026-01-25T15:41:38.695511Z",
     "shell.execute_reply.started": "2026-01-25T15:41:14.405261Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating device features...\n",
      "Device features has been created!\n"
     ]
    }
   ],
   "source": [
    "def create_device_features(df:pd.DataFrame)->pd.DataFrame:\n",
    "    print(\"Creating device features...\")\n",
    "\n",
    "    #device type\n",
    "    df['DeviceType_is_mobile']  = (df.DeviceType == 'mobile').astype(int)\n",
    "    df['DeviceType_is_desktop']  = (df.DeviceType == 'desktop').astype(int)\n",
    "\n",
    "    #device info : it can give important patterns , we just need to specific about multiple \n",
    "    if 'DeviceInfo' in df.columns:\n",
    "        df['Device_brand'] = df.DeviceInfo.apply(\n",
    "            lambda x: str(x).split('/')[0].split()[0] if pd.notna(x) else 'unknown'\n",
    "        )\n",
    "        \n",
    "\n",
    "        #device info length it will show device complexity even strange device could have long name\n",
    "        df['DeviceInfo_length'] = df.DeviceInfo.apply(\n",
    "            lambda x: len(str(x)) if pd.notna(x) else 0\n",
    "        ) \n",
    "\n",
    "\n",
    "        #browser features\n",
    "        if 'id_31' in df.columns:\n",
    "            df['browser'] = df.id_31.apply(lambda x: str(x).split()[0].lower() if pd.notna(x) else 'unknown')\n",
    "            df['Broser_is_chrome'] = df.id_31.apply(lambda x: 1 if pd.notna(x) and 'chrome' in str(x).lower() else 0)\n",
    "            df['Broser_is_firefox'] = df.id_31.apply(lambda x: 1 if pd.notna(x) and 'firefox' in str(x).lower() else 0)\n",
    "            df['Broser_is_edge'] = df.id_31.apply(lambda x: 1 if pd.notna(x) and 'edge' in str(x).lower() else 0)\n",
    "            df['Broser_is_safari'] = df.id_31.apply(lambda x: 1 if pd.notna(x) and 'safari' in str(x).lower() else 0)\n",
    "\n",
    "\n",
    "        #os features from id_30\n",
    "        df[['os_name','os_version']] = df.id_30.fillna('unknown unknown').astype(str).str.split(' ',n=1,expand=True)\n",
    "        \n",
    "        df['OS_is_Windows'] = df['id_30'].apply(\n",
    "            lambda x: 1 if pd.notna(x) and 'windows' in str(x).lower() else 0\n",
    "        )\n",
    "        df['OS_is_Mac'] = df['id_30'].apply(\n",
    "            lambda x: 1 if pd.notna(x) and 'mac' in str(x).lower() else 0\n",
    "        )\n",
    "        df['OS_is_iOS'] = df['id_30'].apply(\n",
    "            lambda x: 1 if pd.notna(x) and 'ios' in str(x).lower() else 0\n",
    "        )\n",
    "        df['OS_is_Android'] = df['id_30'].apply(\n",
    "            lambda x: 1 if pd.notna(x) and 'android' in str(x).lower() else 0\n",
    "        )\n",
    "            \n",
    "    # Screen resolution from id_33\n",
    "    if 'id_33' in df.columns:\n",
    "        df['Screen_width'] = df['id_33'].apply(\n",
    "            lambda x: int(str(x).split('x')[0]) if pd.notna(x) and 'x' in str(x) else -1\n",
    "        )\n",
    "        df['Screen_height'] = df['id_33'].apply(\n",
    "            lambda x: int(str(x).split('x')[1]) if pd.notna(x) and 'x' in str(x) else -1\n",
    "        )\n",
    "        df['Screen_area'] = df['Screen_width'] * df['Screen_height']\n",
    "        df['Screen_aspect_ratio'] = df.apply(\n",
    "            lambda row: row['Screen_width'] / row['Screen_height'] if row['Screen_height'] > 0 else -1, axis=1\n",
    "        )\n",
    "\n",
    "    print('Device features has been created!')\n",
    "    return df\n",
    "\n",
    "Train_df = create_device_features(Train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Address Features üè†\n",
    "\n",
    "**Address columns explained:**\n",
    "- `addr1` ‚Üí Billing region/area code\n",
    "- `addr2` ‚Üí Billing country code (87 = USA in most cases)\n",
    "- `dist1` ‚Üí Distance from card owner's location\n",
    "- `dist2` ‚Üí Distance from recipient's location\n",
    "\n",
    "**Why address matters:**\n",
    "- Missing addresses are suspicious (trying to hide location)\n",
    "- High distances suggest card used far from home\n",
    "- Address + Card combinations detect unusual usage\n",
    "\n",
    "**Features we create:**\n",
    "\n",
    "| Feature | Purpose |\n",
    "|---------|---------|\n",
    "| `addr1_addr2` | Combined location code |\n",
    "| `addr1_ProductCD` | What products are bought from this region |\n",
    "| `addr1_missing` | Flag for missing address (hiding?) |\n",
    "| `both_addr_missing` | Both addresses missing (very suspicious) |\n",
    "| `dist1_log` | Log of distance (normalizes large values) |\n",
    "| `dist2_log` | Log of recipient distance |\n",
    "\n",
    "**Example fraud pattern:**\n",
    "Card registered in addr1=315 (New York) suddenly used from addr1=100 (California) with dist1=2500 miles ‚Üí üö® Alert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:41:38.697321Z",
     "iopub.status.busy": "2026-01-25T15:41:38.697069Z",
     "iopub.status.idle": "2026-01-25T15:41:39.685284Z",
     "shell.execute_reply": "2026-01-25T15:41:39.684423Z",
     "shell.execute_reply.started": "2026-01-25T15:41:38.697300Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating address features...\n",
      "Address features has been created!\n"
     ]
    }
   ],
   "source": [
    "def create_address_features(df):\n",
    "    \"\"\"Create features based on address information\"\"\"\n",
    "    print(\"Creating address features...\")\n",
    "    \n",
    "    # Address combinations\n",
    "    if 'addr1' in df.columns and 'addr2' in df.columns:\n",
    "        df['addr1_addr2'] = df['addr1'].astype(str) + '_' + df['addr2'].astype(str)\n",
    "    \n",
    "    # Address + ProductCD\n",
    "    if 'addr1' in df.columns and 'ProductCD' in df.columns:\n",
    "        df['addr1_ProductCD'] = df['addr1'].astype(str) + '_' + df['ProductCD'].astype(str)\n",
    "    \n",
    "    # Address distance from P_emaildomain (proxy for geographic mismatch)\n",
    "    if 'addr1' in df.columns:\n",
    "        df['addr1_missing'] = df['addr1'].isna().astype(int)\n",
    "    \n",
    "    if 'addr2' in df.columns:\n",
    "        df['addr2_missing'] = df['addr2'].isna().astype(int)\n",
    "    \n",
    "    # Both addresses missing\n",
    "    if 'addr1' in df.columns and 'addr2' in df.columns:\n",
    "        df['both_addr_missing'] = (df['addr1'].isna() & df['addr2'].isna()).astype(int)\n",
    "    \n",
    "    # dist1 and dist2 features\n",
    "    if 'dist1' in df.columns:\n",
    "        df['dist1_missing'] = df['dist1'].isna().astype(int)\n",
    "        df['dist1_log'] = np.log1p(df['dist1'].fillna(0))\n",
    "    \n",
    "    if 'dist2' in df.columns:\n",
    "        df['dist2_missing'] = df['dist2'].isna().astype(int)\n",
    "        df['dist2_log'] = np.log1p(df['dist2'].fillna(0))\n",
    "    print('Address features has been created!')\n",
    "    return df\n",
    "\n",
    "# Apply\n",
    "Train_df = create_address_features(Train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 V-Column Features (Vesta Engineered) üîê\n",
    "\n",
    "**What are V columns?**\n",
    "V1 to V339 are **ANONYMOUS** features created by Vesta Corporation. We don't know what they represent (could be counts, flags, velocities, risk scores, etc.).\n",
    "\n",
    "**The challenge:**\n",
    "339 columns of unknown meaning! How do we use them?\n",
    "\n",
    "**Our approach: Statistical Aggregation**\n",
    "Based on competition analysis, V columns have CORRELATION GROUPS (columns that move together). We aggregate each group:\n",
    "\n",
    "| Group | Columns | What we calculate |\n",
    "|-------|---------|-------------------|\n",
    "| v1 | V1-V11 | sum, mean, std, nan_count |\n",
    "| v2 | V12-V26 | sum, mean, std, nan_count |\n",
    "| v3 | V27-V34 | sum, mean, std, nan_count |\n",
    "| ... | ... | ... |\n",
    "| v7 | V95-V137 | sum, mean, std, nan_count |\n",
    "\n",
    "**Why these aggregations?**\n",
    "- **Sum** ‚Üí Total \"magnitude\" of activity\n",
    "- **Mean** ‚Üí Average value (normalized magnitude)\n",
    "- **Std** ‚Üí Variability (erratic behavior = suspicious)\n",
    "- **NaN count** ‚Üí Missing values (patterns in what's missing)\n",
    "\n",
    "**Overall V statistics:**\n",
    "- `V_sum_all` ‚Üí Sum of ALL V columns\n",
    "- `V_nan_ratio` ‚Üí % of V columns that are missing\n",
    "\n",
    "**Insight:** Fraud transactions often have MORE missing V values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:41:39.686673Z",
     "iopub.status.busy": "2026-01-25T15:41:39.686356Z",
     "iopub.status.idle": "2026-01-25T15:41:47.474853Z",
     "shell.execute_reply": "2026-01-25T15:41:47.474153Z",
     "shell.execute_reply.started": "2026-01-25T15:41:39.686651Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating V-column aggregation features...\n",
      "V-column aggregation features are created!\n"
     ]
    }
   ],
   "source": [
    "def create_v_features(df):\n",
    "    \"\"\"Create aggregation features from V columns\"\"\"\n",
    "    print(\"Creating V-column aggregation features...\")\n",
    "    \n",
    "    # Get all V columns\n",
    "    v_cols = [col for col in df.columns if col.startswith('V')]\n",
    "    \n",
    "    if len(v_cols) == 0:\n",
    "        return df\n",
    "    \n",
    "    # Group V columns by their correlation patterns (based on EDA from competition)\n",
    "    v_groups = {\n",
    "        'v1': ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11'],\n",
    "        'v2': ['V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26'],\n",
    "        'v3': ['V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34'],\n",
    "        'v4': ['V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52'],\n",
    "        'v5': ['V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74'],\n",
    "        'v6': ['V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94'],\n",
    "        'v7': ['V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137'],\n",
    "    }\n",
    "    \n",
    "    for group_name, group_cols in v_groups.items():\n",
    "        # Filter to existing columns\n",
    "        existing_cols = [col for col in group_cols if col in df.columns]\n",
    "        \n",
    "        if len(existing_cols) > 0:\n",
    "            # Sum of group\n",
    "            df[f'{group_name}_sum'] = df[existing_cols].sum(axis=1)\n",
    "            \n",
    "            # Mean of group\n",
    "            df[f'{group_name}_mean'] = df[existing_cols].mean(axis=1)\n",
    "            \n",
    "            # Std of group\n",
    "            df[f'{group_name}_std'] = df[existing_cols].std(axis=1)\n",
    "            \n",
    "            # NaN count in group\n",
    "            df[f'{group_name}_nan_count'] = df[existing_cols].isna().sum(axis=1)\n",
    "    \n",
    "    # Overall V statistics\n",
    "    existing_v_cols = [col for col in v_cols if col in df.columns]\n",
    "    if len(existing_v_cols) > 0:\n",
    "        df['V_sum_all'] = df[existing_v_cols].sum(axis=1)\n",
    "        df['V_mean_all'] = df[existing_v_cols].mean(axis=1)\n",
    "        df['V_std_all'] = df[existing_v_cols].std(axis=1)\n",
    "        df['V_nan_count_all'] = df[existing_v_cols].isna().sum(axis=1)\n",
    "        df['V_nan_ratio'] = df['V_nan_count_all'] / len(existing_v_cols)\n",
    "    print(\"V-column aggregation features are created!\")    \n",
    "    return df\n",
    "\n",
    "# Apply\n",
    "Train_df = create_v_features(Train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 C and D Column Features üìä\n",
    "\n",
    "**What are C columns? (C1-C14)**\n",
    "\"C\" stands for **Counting** features. They count things like:\n",
    "- Number of addresses associated with this card\n",
    "- Number of email addresses used\n",
    "- Number of devices used\n",
    "- etc. (exact meanings are anonymous)\n",
    "\n",
    "**What are D columns? (D1-D15)**\n",
    "\"D\" stands for **Days/Timedelta** features. They measure time since events:\n",
    "- D1 = Days since first transaction\n",
    "- D15 = Days since account creation\n",
    "- etc. (exact meanings are anonymous)\n",
    "\n",
    "**Key finding from competition:**\n",
    "D1 and D15 are the MOST IMPORTANT D features!\n",
    "\n",
    "**Features we create:**\n",
    "\n",
    "For key columns (card1, card2, addr1):\n",
    "\n",
    "| Feature | Formula | Purpose |\n",
    "|---------|---------|---------|\n",
    "| `{col}_freq` | Count of this value | Common cards vs rare cards |\n",
    "| `{col}_TransactionAmt_mean` | Avg spending for this entity | Normal behavior baseline |\n",
    "| `{col}_TransactionAmt_std` | Spending variability | Consistent vs erratic |\n",
    "| `{col}_TransactionAmt_dev` | current - mean | Is THIS transaction unusual? |\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "card1 = 13926\n",
    "card1_TransactionAmt_mean = $75\n",
    "card1_TransactionAmt_std = $20\n",
    "Current transaction = $500\n",
    "\n",
    "card1_TransactionAmt_dev = $500 - $75 = $425 (21 std deviations!) üö®\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:41:47.476211Z",
     "iopub.status.busy": "2026-01-25T15:41:47.475876Z",
     "iopub.status.idle": "2026-01-25T15:41:51.035818Z",
     "shell.execute_reply": "2026-01-25T15:41:51.035091Z",
     "shell.execute_reply.started": "2026-01-25T15:41:47.476185Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating aggregation features...\n",
      "C and D Column Features has been implemented...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "def create_aggregation_features(train_df):\n",
    "    \"\"\"Create frequency and aggregation features for both train and test\"\"\"\n",
    "    print(\"Creating aggregation features...\")\n",
    "    \n",
    "    # 1. Create copies to avoid SettingWithCopy warnings on original dfs\n",
    "    train_df = train_df.copy()\n",
    "    \n",
    "    # 3. Columns for frequency encoding\n",
    "    freq_cols = ['card1', 'card2', 'card3', 'card4', 'card5', 'card6', \n",
    "                 'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain',\n",
    "                 'ProductCD', 'DeviceType', 'DeviceInfo']\n",
    "    \n",
    "    for col in freq_cols:\n",
    "        if col in train_df.columns:\n",
    "            # Frequency encoding\n",
    "            freq = train_df[col].value_counts().to_dict()\n",
    "            train_df[f'{col}_freq'] = train_df[col].map(freq)\n",
    "    \n",
    "    # 4. Transaction amount aggregations\n",
    "    # Note: 'card1_card2' must exist in df before running this\n",
    "    agg_cols = ['card1', 'card2', 'addr1'] \n",
    "    \n",
    "    for col in agg_cols:\n",
    "        if col in train_df.columns:\n",
    "            # Mean transaction amount\n",
    "            agg_mean = train_df.groupby(col)['TransactionAmt'].mean().to_dict()\n",
    "            train_df[f'{col}_TransactionAmt_mean'] = train_df[col].map(agg_mean)\n",
    "            \n",
    "            # Std transaction amount\n",
    "            agg_std = train_df.groupby(col)['TransactionAmt'].std().to_dict()\n",
    "            train_df[f'{col}_TransactionAmt_std'] = train_df[col].map(agg_std)\n",
    "            \n",
    "            # Transaction amount deviation from mean\n",
    "            train_df[f'{col}_TransactionAmt_dev'] = train_df['TransactionAmt'] - train_df[f'{col}_TransactionAmt_mean']\n",
    "    \n",
    "    print(\"C and D Column Features has been implemented...\")\n",
    "    return train_df\n",
    "\n",
    "# Usage: Update BOTH dataframes\n",
    "Train_df= create_aggregation_features(Train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:41:51.037082Z",
     "iopub.status.busy": "2026-01-25T15:41:51.036842Z",
     "iopub.status.idle": "2026-01-25T15:41:51.101191Z",
     "shell.execute_reply": "2026-01-25T15:41:51.100546Z",
     "shell.execute_reply.started": "2026-01-25T15:41:51.037062Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>P_emaildomain</th>\n",
       "      <th>R_emaildomain</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>D10</th>\n",
       "      <th>D11</th>\n",
       "      <th>D12</th>\n",
       "      <th>D13</th>\n",
       "      <th>D14</th>\n",
       "      <th>D15</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>...</th>\n",
       "      <th>v2_mean</th>\n",
       "      <th>v2_std</th>\n",
       "      <th>v2_nan_count</th>\n",
       "      <th>v3_sum</th>\n",
       "      <th>v3_mean</th>\n",
       "      <th>v3_std</th>\n",
       "      <th>v3_nan_count</th>\n",
       "      <th>v4_sum</th>\n",
       "      <th>v4_mean</th>\n",
       "      <th>v4_std</th>\n",
       "      <th>v4_nan_count</th>\n",
       "      <th>v5_sum</th>\n",
       "      <th>v5_mean</th>\n",
       "      <th>v5_std</th>\n",
       "      <th>v5_nan_count</th>\n",
       "      <th>v6_sum</th>\n",
       "      <th>v6_mean</th>\n",
       "      <th>v6_std</th>\n",
       "      <th>v6_nan_count</th>\n",
       "      <th>v7_sum</th>\n",
       "      <th>v7_mean</th>\n",
       "      <th>v7_std</th>\n",
       "      <th>v7_nan_count</th>\n",
       "      <th>V_sum_all</th>\n",
       "      <th>V_mean_all</th>\n",
       "      <th>V_std_all</th>\n",
       "      <th>V_nan_count_all</th>\n",
       "      <th>V_nan_ratio</th>\n",
       "      <th>card1_freq</th>\n",
       "      <th>card2_freq</th>\n",
       "      <th>card3_freq</th>\n",
       "      <th>card4_freq</th>\n",
       "      <th>card5_freq</th>\n",
       "      <th>card6_freq</th>\n",
       "      <th>addr1_freq</th>\n",
       "      <th>addr2_freq</th>\n",
       "      <th>P_emaildomain_freq</th>\n",
       "      <th>R_emaildomain_freq</th>\n",
       "      <th>ProductCD_freq</th>\n",
       "      <th>DeviceType_freq</th>\n",
       "      <th>DeviceInfo_freq</th>\n",
       "      <th>card1_TransactionAmt_mean</th>\n",
       "      <th>card1_TransactionAmt_std</th>\n",
       "      <th>card1_TransactionAmt_dev</th>\n",
       "      <th>card2_TransactionAmt_mean</th>\n",
       "      <th>card2_TransactionAmt_std</th>\n",
       "      <th>card2_TransactionAmt_dev</th>\n",
       "      <th>addr1_TransactionAmt_mean</th>\n",
       "      <th>addr1_TransactionAmt_std</th>\n",
       "      <th>addr1_TransactionAmt_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182988</th>\n",
       "      <td>3169988</td>\n",
       "      <td>0</td>\n",
       "      <td>4050851</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>W</td>\n",
       "      <td>10000</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>184.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>missing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.501631</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.428932</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.444262</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.266272</td>\n",
       "      <td>0.443321</td>\n",
       "      <td>170</td>\n",
       "      <td>0.501475</td>\n",
       "      <td>1</td>\n",
       "      <td>45191</td>\n",
       "      <td>521287</td>\n",
       "      <td>189217</td>\n",
       "      <td>25941</td>\n",
       "      <td>439938</td>\n",
       "      <td>15160.0</td>\n",
       "      <td>520481.0</td>\n",
       "      <td>228355</td>\n",
       "      <td>453249</td>\n",
       "      <td>439670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148.895889</td>\n",
       "      <td>242.668839</td>\n",
       "      <td>-119.895889</td>\n",
       "      <td>141.490036</td>\n",
       "      <td>240.664474</td>\n",
       "      <td>-112.490036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341484</th>\n",
       "      <td>3328484</td>\n",
       "      <td>0</td>\n",
       "      <td>8421815</td>\n",
       "      <td>39.394001</td>\n",
       "      <td>C</td>\n",
       "      <td>10003</td>\n",
       "      <td>555.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.351866</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.652998</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.444262</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0</td>\n",
       "      <td>714.106201</td>\n",
       "      <td>2.541303</td>\n",
       "      <td>8.895429</td>\n",
       "      <td>58</td>\n",
       "      <td>0.171091</td>\n",
       "      <td>5</td>\n",
       "      <td>41995</td>\n",
       "      <td>7</td>\n",
       "      <td>384767</td>\n",
       "      <td>296546</td>\n",
       "      <td>439938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>228355</td>\n",
       "      <td>57147</td>\n",
       "      <td>68519</td>\n",
       "      <td>55645.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.222401</td>\n",
       "      <td>14.039614</td>\n",
       "      <td>13.171600</td>\n",
       "      <td>125.703545</td>\n",
       "      <td>205.944016</td>\n",
       "      <td>-86.309544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350343</th>\n",
       "      <td>3337343</td>\n",
       "      <td>0</td>\n",
       "      <td>8634882</td>\n",
       "      <td>10.755000</td>\n",
       "      <td>C</td>\n",
       "      <td>10003</td>\n",
       "      <td>555.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.916666</td>\n",
       "      <td>0.916666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.652998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0</td>\n",
       "      <td>937.328430</td>\n",
       "      <td>3.857319</td>\n",
       "      <td>14.890990</td>\n",
       "      <td>96</td>\n",
       "      <td>0.283186</td>\n",
       "      <td>5</td>\n",
       "      <td>41995</td>\n",
       "      <td>7</td>\n",
       "      <td>384767</td>\n",
       "      <td>296546</td>\n",
       "      <td>439938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94456</td>\n",
       "      <td>453249</td>\n",
       "      <td>68519</td>\n",
       "      <td>55645.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.222401</td>\n",
       "      <td>14.039614</td>\n",
       "      <td>-15.467401</td>\n",
       "      <td>125.703545</td>\n",
       "      <td>205.944016</td>\n",
       "      <td>-114.948545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350365</th>\n",
       "      <td>3337365</td>\n",
       "      <td>0</td>\n",
       "      <td>8635215</td>\n",
       "      <td>19.093000</td>\n",
       "      <td>C</td>\n",
       "      <td>10003</td>\n",
       "      <td>555.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.916666</td>\n",
       "      <td>0.916666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.652998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0</td>\n",
       "      <td>1222.443604</td>\n",
       "      <td>5.030632</td>\n",
       "      <td>16.538343</td>\n",
       "      <td>96</td>\n",
       "      <td>0.283186</td>\n",
       "      <td>5</td>\n",
       "      <td>41995</td>\n",
       "      <td>7</td>\n",
       "      <td>384767</td>\n",
       "      <td>296546</td>\n",
       "      <td>439938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94456</td>\n",
       "      <td>453249</td>\n",
       "      <td>68519</td>\n",
       "      <td>55645.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.222401</td>\n",
       "      <td>14.039614</td>\n",
       "      <td>-7.129400</td>\n",
       "      <td>125.703545</td>\n",
       "      <td>205.944016</td>\n",
       "      <td>-106.610544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350822</th>\n",
       "      <td>3337822</td>\n",
       "      <td>0</td>\n",
       "      <td>8642405</td>\n",
       "      <td>19.093000</td>\n",
       "      <td>C</td>\n",
       "      <td>10003</td>\n",
       "      <td>555.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.652998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0</td>\n",
       "      <td>773.089600</td>\n",
       "      <td>3.181439</td>\n",
       "      <td>13.720274</td>\n",
       "      <td>96</td>\n",
       "      <td>0.283186</td>\n",
       "      <td>5</td>\n",
       "      <td>41995</td>\n",
       "      <td>7</td>\n",
       "      <td>384767</td>\n",
       "      <td>296546</td>\n",
       "      <td>439938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94456</td>\n",
       "      <td>453249</td>\n",
       "      <td>68519</td>\n",
       "      <td>85165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.222401</td>\n",
       "      <td>14.039614</td>\n",
       "      <td>-7.129400</td>\n",
       "      <td>125.703545</td>\n",
       "      <td>205.944016</td>\n",
       "      <td>-106.610544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 555 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  \\\n",
       "182988        3169988        0        4050851       29.000000         W   \n",
       "341484        3328484        0        8421815       39.394001         C   \n",
       "350343        3337343        0        8634882       10.755000         C   \n",
       "350365        3337365        0        8635215       19.093000         C   \n",
       "350822        3337822        0        8642405       19.093000         C   \n",
       "\n",
       "        card1  card2  card3       card4  card5  card6  addr1  addr2  dist1  \\\n",
       "182988  10000  111.0  150.0  mastercard  117.0  debit  184.0   87.0    NaN   \n",
       "341484  10003  555.0  128.0        visa  226.0  debit    NaN    NaN    NaN   \n",
       "350343  10003  555.0  128.0        visa  226.0  debit    NaN    NaN    NaN   \n",
       "350365  10003  555.0  128.0        visa  226.0  debit    NaN    NaN    NaN   \n",
       "350822  10003  555.0  128.0        visa  226.0  debit    NaN    NaN    NaN   \n",
       "\n",
       "        dist2 P_emaildomain R_emaildomain   C1   C2   C3   C4   C5   C6   C7  \\\n",
       "182988    NaN     gmail.com       missing  1.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "341484    NaN     gmail.com     gmail.com  1.0  2.0  0.0  1.0  0.0  1.0  1.0   \n",
       "350343    NaN       missing       missing  1.0  3.0  0.0  1.0  0.0  1.0  1.0   \n",
       "350365    NaN       missing       missing  1.0  4.0  0.0  1.0  0.0  1.0  1.0   \n",
       "350822    NaN       missing       missing  1.0  5.0  0.0  1.0  0.0  1.0  1.0   \n",
       "\n",
       "         C8   C9  C10  C11  C12  C13  C14    D1    D2    D3    D4    D5   D6  \\\n",
       "182988  0.0  0.0  0.0  1.0  0.0  4.0  1.0  83.0  83.0  70.0  70.0  70.0  NaN   \n",
       "341484  1.0  0.0  2.0  2.0  2.0  2.0  1.0   7.0   7.0   7.0   7.0   7.0  7.0   \n",
       "350343  1.0  0.0  3.0  2.0  2.0  3.0  1.0   9.0   9.0   2.0   NaN   NaN  NaN   \n",
       "350365  1.0  0.0  3.0  2.0  2.0  3.0  1.0   9.0   9.0   0.0   NaN   NaN  NaN   \n",
       "350822  2.0  0.0  4.0  2.0  2.0  4.0  1.0  10.0  10.0   0.0   NaN   NaN  NaN   \n",
       "\n",
       "         D7          D8        D9   D10  D11  D12  D13  D14   D15   M1   M2  \\\n",
       "182988  NaN         NaN       NaN  83.0  NaN  NaN  NaN  NaN  83.0  NaN  NaN   \n",
       "341484  7.0    7.458333  0.458333   0.0  NaN  7.0  7.0  0.0   0.0  NaN  NaN   \n",
       "350343  NaN    9.916666  0.916666   0.0  NaN  NaN  9.0  0.0   NaN  NaN  NaN   \n",
       "350365  NaN    9.916666  0.916666   0.0  NaN  NaN  9.0  0.0   NaN  NaN  NaN   \n",
       "350822  NaN  139.000000  0.000000   0.0  NaN  NaN  0.0  0.0   NaN  NaN  NaN   \n",
       "\n",
       "         M3   M4  ...   v2_mean    v2_std v2_nan_count v3_sum v3_mean  \\\n",
       "182988  NaN   M0  ...  0.333333  0.487950            0    0.0     0.0   \n",
       "341484  NaN   M2  ...  0.866667  0.351866            0    4.0     0.5   \n",
       "350343  NaN  NaN  ...  0.466667  0.516398            0    0.0     0.0   \n",
       "350365  NaN  NaN  ...  0.466667  0.516398            0    0.0     0.0   \n",
       "350822  NaN  NaN  ...  0.466667  0.516398            0    0.0     0.0   \n",
       "\n",
       "          v3_std  v3_nan_count  v4_sum   v4_mean    v4_std  v4_nan_count  \\\n",
       "182988  0.000000             0     7.0  0.388889  0.501631             0   \n",
       "341484  0.534522             0    18.0  1.000000  0.685994             0   \n",
       "350343  0.000000             0     0.0       NaN       NaN            18   \n",
       "350365  0.000000             0     0.0       NaN       NaN            18   \n",
       "350822  0.000000             0     0.0       NaN       NaN            18   \n",
       "\n",
       "        v5_sum   v5_mean    v5_std  v5_nan_count  v6_sum  v6_mean    v6_std  \\\n",
       "182988     5.0  0.227273  0.428932             0     5.0     0.25  0.444262   \n",
       "341484    21.0  0.954545  0.652998             0    15.0     0.75  0.444262   \n",
       "350343    21.0  0.954545  0.652998             0     0.0      NaN       NaN   \n",
       "350365    21.0  0.954545  0.652998             0     0.0      NaN       NaN   \n",
       "350822    21.0  0.954545  0.652998             0     0.0      NaN       NaN   \n",
       "\n",
       "        v6_nan_count  v7_sum  v7_mean    v7_std  v7_nan_count    V_sum_all  \\\n",
       "182988             0    19.0  0.44186  0.502486             0    45.000000   \n",
       "341484             0    19.0  0.44186  0.502486             0   714.106201   \n",
       "350343            20    19.0  0.44186  0.502486             0   937.328430   \n",
       "350365            20    19.0  0.44186  0.502486             0  1222.443604   \n",
       "350822            20    19.0  0.44186  0.502486             0   773.089600   \n",
       "\n",
       "        V_mean_all  V_std_all  V_nan_count_all  V_nan_ratio  card1_freq  \\\n",
       "182988    0.266272   0.443321              170     0.501475           1   \n",
       "341484    2.541303   8.895429               58     0.171091           5   \n",
       "350343    3.857319  14.890990               96     0.283186           5   \n",
       "350365    5.030632  16.538343               96     0.283186           5   \n",
       "350822    3.181439  13.720274               96     0.283186           5   \n",
       "\n",
       "        card2_freq  card3_freq  card4_freq  card5_freq  card6_freq  \\\n",
       "182988       45191      521287      189217       25941      439938   \n",
       "341484       41995           7      384767      296546      439938   \n",
       "350343       41995           7      384767      296546      439938   \n",
       "350365       41995           7      384767      296546      439938   \n",
       "350822       41995           7      384767      296546      439938   \n",
       "\n",
       "        addr1_freq  addr2_freq  P_emaildomain_freq  R_emaildomain_freq  \\\n",
       "182988     15160.0    520481.0              228355              453249   \n",
       "341484         NaN         NaN              228355               57147   \n",
       "350343         NaN         NaN               94456              453249   \n",
       "350365         NaN         NaN               94456              453249   \n",
       "350822         NaN         NaN               94456              453249   \n",
       "\n",
       "        ProductCD_freq  DeviceType_freq  DeviceInfo_freq  \\\n",
       "182988          439670              NaN              NaN   \n",
       "341484           68519          55645.0              5.0   \n",
       "350343           68519          55645.0              5.0   \n",
       "350365           68519          55645.0              5.0   \n",
       "350822           68519          85165.0              NaN   \n",
       "\n",
       "        card1_TransactionAmt_mean  card1_TransactionAmt_std  \\\n",
       "182988                  29.000000                       NaN   \n",
       "341484                  26.222401                 14.039614   \n",
       "350343                  26.222401                 14.039614   \n",
       "350365                  26.222401                 14.039614   \n",
       "350822                  26.222401                 14.039614   \n",
       "\n",
       "        card1_TransactionAmt_dev  card2_TransactionAmt_mean  \\\n",
       "182988                  0.000000                 148.895889   \n",
       "341484                 13.171600                 125.703545   \n",
       "350343                -15.467401                 125.703545   \n",
       "350365                 -7.129400                 125.703545   \n",
       "350822                 -7.129400                 125.703545   \n",
       "\n",
       "        card2_TransactionAmt_std  card2_TransactionAmt_dev  \\\n",
       "182988                242.668839               -119.895889   \n",
       "341484                205.944016                -86.309544   \n",
       "350343                205.944016               -114.948545   \n",
       "350365                205.944016               -106.610544   \n",
       "350822                205.944016               -106.610544   \n",
       "\n",
       "        addr1_TransactionAmt_mean  addr1_TransactionAmt_std  \\\n",
       "182988                 141.490036                240.664474   \n",
       "341484                        NaN                       NaN   \n",
       "350343                        NaN                       NaN   \n",
       "350365                        NaN                       NaN   \n",
       "350822                        NaN                       NaN   \n",
       "\n",
       "        addr1_TransactionAmt_dev  \n",
       "182988               -112.490036  \n",
       "341484                       NaN  \n",
       "350343                       NaN  \n",
       "350365                       NaN  \n",
       "350822                       NaN  \n",
       "\n",
       "[5 rows x 555 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.10 ID Features (Identity Verification) üÜî\n",
    "\n",
    "**What are ID columns?**\n",
    "ID features contain identity verification results from Vesta's fraud prevention system.\n",
    "\n",
    "**ID column groups:**\n",
    "\n",
    "| Columns | Type | Description |\n",
    "|---------|------|-------------|\n",
    "| id_01 to id_11 | Numerical | Verification scores/counts |\n",
    "| id_12 to id_38 | Categorical | Verification results (Found/NotFound/New) |\n",
    "\n",
    "**Key categorical features:**\n",
    "- `id_12` = \"Found\" or \"NotFound\" (identity verification)\n",
    "- `id_15` = \"Found\", \"New\", or \"Unknown\" (device recognition)\n",
    "- `id_16` = \"Found\" or \"NotFound\" (matching status)\n",
    "- `id_28` = \"Found\" or \"New\" (identity type)\n",
    "- `id_29` = \"Found\" or \"NotFound\" (matching verification)\n",
    "- `id_34` = \"match_status:X\" (similarity score)\n",
    "\n",
    "**Why \"New\" devices are risky:**\n",
    "- First-time device = no history to verify\n",
    "- Fraud often uses fresh/unknown devices\n",
    "- Legitimate users tend to use same devices repeatedly\n",
    "\n",
    "**Features we create:**\n",
    "\n",
    "| Feature | Purpose |\n",
    "|---------|---------|\n",
    "| `id_num_nan_count` | How many numerical IDs are missing |\n",
    "| `id_num_mean/std` | Average and variability of ID scores |\n",
    "| `id_15_isNew` | Flag for new/unknown device |\n",
    "| `id_15_isFound` | Flag for recognized device |\n",
    "| `id_34_match` | Extract match score from \"match_status:X\" |\n",
    "| `id_36/37/38_isT` | Various T/F verification flags |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:41:51.102489Z",
     "iopub.status.busy": "2026-01-25T15:41:51.102179Z",
     "iopub.status.idle": "2026-01-25T15:41:51.897646Z",
     "shell.execute_reply": "2026-01-25T15:41:51.897026Z",
     "shell.execute_reply.started": "2026-01-25T15:41:51.102457Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ID features...\n"
     ]
    }
   ],
   "source": [
    "def create_id_features(df):\n",
    "    \"\"\"Create features from identity columns\"\"\"\n",
    "    print(\"Creating ID features...\")\n",
    "    \n",
    "    # id_01 to id_11 are numerical\n",
    "    id_num_cols = [f'id_0{i}' for i in range(1, 10)] + ['id_10', 'id_11']\n",
    "    existing_id_num = [col for col in id_num_cols if col in df.columns]\n",
    "    \n",
    "    if len(existing_id_num) > 0:\n",
    "        df['id_num_nan_count'] = df[existing_id_num].isna().sum(axis=1)\n",
    "        df['id_num_mean'] = df[existing_id_num].mean(axis=1)\n",
    "        df['id_num_std'] = df[existing_id_num].std(axis=1)\n",
    "    \n",
    "    # id_12 to id_38 are categorical\n",
    "    # Check specific important ones\n",
    "    if 'id_12' in df.columns:\n",
    "        df['id_12_isFound'] = (df['id_12'] == 'Found').astype(int)\n",
    "    \n",
    "    if 'id_15' in df.columns:\n",
    "        df['id_15_isNew'] = (df['id_15'] == 'New').astype(int)\n",
    "        df['id_15_isFound'] = (df['id_15'] == 'Found').astype(int)\n",
    "    \n",
    "    if 'id_16' in df.columns:\n",
    "        df['id_16_isFound'] = (df['id_16'] == 'Found').astype(int)\n",
    "    \n",
    "    if 'id_28' in df.columns:\n",
    "        df['id_28_isNew'] = (df['id_28'] == 'New').astype(int)\n",
    "        df['id_28_isFound'] = (df['id_28'] == 'Found').astype(int)\n",
    "    \n",
    "    if 'id_29' in df.columns:\n",
    "        df['id_29_isFound'] = (df['id_29'] == 'Found').astype(int)\n",
    "    \n",
    "    # id_34 (match status)\n",
    "    if 'id_34' in df.columns:\n",
    "        df['id_34_match'] = df['id_34'].apply(\n",
    "            lambda x: int(str(x).split(':')[1]) if pd.notna(x) and ':' in str(x) else -1\n",
    "        )\n",
    "    \n",
    "    # id_36 features\n",
    "    if 'id_36' in df.columns:\n",
    "        df['id_36_isT'] = (df['id_36'] == 'T').astype(int)\n",
    "    \n",
    "    # id_37, id_38 features\n",
    "    if 'id_37' in df.columns:\n",
    "        df['id_37_isT'] = (df['id_37'] == 'T').astype(int)\n",
    "    \n",
    "    if 'id_38' in df.columns:\n",
    "        df['id_38_isT'] = (df['id_38'] == 'T').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply\n",
    "Train_df = create_id_features(Train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.11 Feature Engineering Summary ‚úÖ\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "| Metric | Before | After |\n",
    "|--------|--------|-------|\n",
    "| Number of features | 434 | 569 |\n",
    "| New features created | - | 135 |\n",
    "| Memory usage | 1,955 MB | 1,335 MB |\n",
    "| Memory saved | - | 31% |\n",
    "\n",
    "**Feature categories created:**\n",
    "\n",
    "| Category | Features | Purpose |\n",
    "|----------|----------|---------|\n",
    "| Transaction Amount | 12 | Spending patterns, spikes, bot detection |\n",
    "| Time | 9 | Night/business hours, velocity, gaps |\n",
    "| Card | 6 | User fingerprints, combinations |\n",
    "| Email | 8 | Domain risk, matching, providers |\n",
    "| Device | 15 | Browser, OS, screen, brand |\n",
    "| Address | 7 | Location patterns, distances |\n",
    "| V-aggregations | 33 | Anonymous feature summaries |\n",
    "| C/D aggregations | 22 | Counting and time patterns |\n",
    "| ID features | 14 | Verification flags and scores |\n",
    "\n",
    "**Next steps:**\n",
    "1. Handle remaining missing values\n",
    "2. Encode categorical features (Label Encoding)\n",
    "3. Train LightGBM model\n",
    "4. Evaluate with ROC-AUC\n",
    "5. Feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:41:51.898854Z",
     "iopub.status.busy": "2026-01-25T15:41:51.898563Z",
     "iopub.status.idle": "2026-01-25T15:41:53.351929Z",
     "shell.execute_reply": "2026-01-25T15:41:53.350854Z",
     "shell.execute_reply.started": "2026-01-25T15:41:51.898826Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "No. of Features befor Data Preprocessing: 434\n",
      "No. of Features after Data Preprocessing: 569\n",
      "No. of New features created: 135\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Applying memory reduction ...\n",
      "\n",
      "\n",
      "Memory usage: 1609.37 MB -> 1335.66 MB (17.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "original_no_of_features = 434\n",
    "new_features = Train_df.shape[1] - original_no_of_features\n",
    "\n",
    "print(f\"\"\"\n",
    "\n",
    "No. of Features befor Data Preprocessing: {original_no_of_features}\n",
    "No. of Features after Data Preprocessing: {Train_df.shape[1]}\n",
    "No. of New features created: {new_features}\n",
    "\n",
    "----------------------------------------------------------------------------\n",
    "Applying memory reduction ...\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "Train_df = reduce_memory(Train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• ENHANCED FEATURE ENGINEERING (NEW - For AUC > 0.98)\n",
    "\n",
    "## The sections below add **winning solution techniques** to boost performance:\n",
    "\n",
    "| Technique | Description | Impact |\n",
    "|-----------|-------------|--------|\n",
    "| **UID Magic Features** | Create unique user IDs from card1+addr1+D1 | üî• HUGE |\n",
    "| **UID Aggregations** | Mean/std/count per user | HIGH |\n",
    "| **Time Velocity** | Time since last transaction, rapid-fire detection | HIGH |\n",
    "| **Enhanced Frequency** | Normalized frequency encoding | MEDIUM |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üÜï 5.12 UID Magic Features (THE KEY TO WINNING!)\n",
    "\n",
    "**What is UID?**\n",
    "UID = Unique User ID. By combining `card1 + addr1 + D1`, we can identify the SAME credit card holder across multiple transactions.\n",
    "\n",
    "**Why is this powerful?**\n",
    "- Once we know WHO is making the transaction, we can ask: \"Is this unusual for THIS person?\"\n",
    "- Fraudsters behave differently than legitimate users - UID helps capture this!\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "card1=13926, addr1=315, D1=14 ‚Üí UID = \"13926_315_14\"\n",
    "All transactions with this UID are from the same card!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üî• NEW: UID MAGIC FEATURES\n",
    "# ========================================\n",
    "# This is THE most important technique from winning solutions!\n",
    "\n",
    "def create_uid_features(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Create UID (Unique User ID) - The MAGIC feature!\n",
    "    card1 + addr1 + D1 can identify unique credit card holders.\n",
    "    \"\"\"\n",
    "    print(\"üî• Creating UID magic features...\")\n",
    "    \n",
    "    # Combine train and test for consistent encoding\n",
    "    train_df['is_train'] = 1\n",
    "    test_df['is_train'] = 0\n",
    "    df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    # UID TYPE 1: card1 + addr1 (location-based)\n",
    "    df['uid1'] = df['card1'].astype(str) + '_' + df['addr1'].astype(str)\n",
    "    \n",
    "    # UID TYPE 2: card1 + addr1 + D1 (time-based) - MOST POWERFUL!\n",
    "    df['uid2'] = df['card1'].astype(str) + '_' + df['addr1'].astype(str) + '_' + df['D1'].astype(str)\n",
    "    \n",
    "    # UID TYPE 3: Full card fingerprint\n",
    "    df['uid3'] = (df['card1'].astype(str) + '_' + \n",
    "                  df['card2'].astype(str) + '_' + \n",
    "                  df['card3'].astype(str) + '_' + \n",
    "                  df['card4'].astype(str) + '_' + \n",
    "                  df['card5'].astype(str) + '_' + \n",
    "                  df['card6'].astype(str))\n",
    "    \n",
    "    # UID TYPE 4: card + email domain\n",
    "    df['uid4'] = df['card1'].astype(str) + '_' + df['P_emaildomain'].astype(str)\n",
    "    \n",
    "    print(f\"  ‚úì uid1 unique values: {df['uid1'].nunique():,}\")\n",
    "    print(f\"  ‚úì uid2 unique values: {df['uid2'].nunique():,}\")\n",
    "    print(f\"  ‚úì uid3 unique values: {df['uid3'].nunique():,}\")\n",
    "    print(f\"  ‚úì uid4 unique values: {df['uid4'].nunique():,}\")\n",
    "    \n",
    "    # Split back\n",
    "    train_df = df[df['is_train'] == 1].drop('is_train', axis=1)\n",
    "    test_df = df[df['is_train'] == 0].drop('is_train', axis=1)\n",
    "    \n",
    "    del df\n",
    "    gc.collect()\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# Apply UID features\n",
    "Train_df, Test_df = create_uid_features(Train_df, Test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üÜï 5.13 UID-Based Aggregation Features\n",
    "\n",
    "Now that we have UIDs, we create POWERFUL aggregated features:\n",
    "- **Transaction count per user** - How active is this user?\n",
    "- **Mean/Std amount per user** - What's their typical spending?\n",
    "- **Amount ratio** - Is THIS transaction unusual for this user?\n",
    "\n",
    "**Key insight:** Fraud is CONTEXTUAL. $500 may be normal for one user but suspicious for another!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üî• NEW: UID AGGREGATION FEATURES\n",
    "# ========================================\n",
    "\n",
    "def create_uid_aggregations(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Create aggregation features based on UID.\n",
    "    These features capture user behavior patterns.\n",
    "    \"\"\"\n",
    "    print(\"üî• Creating UID aggregation features...\")\n",
    "    \n",
    "    train_df['is_train'] = 1\n",
    "    test_df['is_train'] = 0\n",
    "    df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "    df = df.sort_values('TransactionDT').reset_index(drop=True)\n",
    "    \n",
    "    uid_cols = ['uid1', 'uid2', 'uid3', 'uid4']\n",
    "    \n",
    "    for uid in uid_cols:\n",
    "        print(f\"  Processing {uid}...\")\n",
    "        \n",
    "        # Transaction count per UID\n",
    "        df[f'{uid}_count'] = df.groupby(uid)['TransactionID'].transform('count')\n",
    "        \n",
    "        # Transaction amount statistics\n",
    "        df[f'{uid}_TransactionAmt_mean'] = df.groupby(uid)['TransactionAmt'].transform('mean')\n",
    "        df[f'{uid}_TransactionAmt_std'] = df.groupby(uid)['TransactionAmt'].transform('std')\n",
    "        \n",
    "        # How unusual is THIS transaction for this user?\n",
    "        df[f'{uid}_TransactionAmt_to_mean'] = df['TransactionAmt'] / (df[f'{uid}_TransactionAmt_mean'] + 0.001)\n",
    "        df[f'{uid}_TransactionAmt_to_std'] = (df['TransactionAmt'] - df[f'{uid}_TransactionAmt_mean']) / (df[f'{uid}_TransactionAmt_std'] + 0.001)\n",
    "        \n",
    "        # Time-based features per UID\n",
    "        df[f'{uid}_D1_mean'] = df.groupby(uid)['D1'].transform('mean')\n",
    "    \n",
    "    # Split back\n",
    "    train_df = df[df['is_train'] == 1].drop('is_train', axis=1)\n",
    "    test_df = df[df['is_train'] == 0].drop('is_train', axis=1)\n",
    "    \n",
    "    del df\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"  ‚úì Created {len(uid_cols) * 6} UID aggregation features\")\n",
    "    return train_df, test_df\n",
    "\n",
    "Train_df, Test_df = create_uid_aggregations(Train_df, Test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üÜï 5.14 Time Velocity Features\n",
    "\n",
    "**Key fraud pattern:** Fraudsters make RAPID transactions before the card gets blocked!\n",
    "\n",
    "We create:\n",
    "- **Time since last transaction** - Is this too fast?\n",
    "- **Is rapid flag** - < 1 hour since last = suspicious!\n",
    "- **Transaction count in session** - How many transactions in this burst?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üî• NEW: TIME VELOCITY FEATURES\n",
    "# ========================================\n",
    "\n",
    "def create_velocity_features(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Create velocity features - detects rapid-fire fraud!\n",
    "    \"\"\"\n",
    "    print(\"üî• Creating time velocity features...\")\n",
    "    \n",
    "    train_df['is_train'] = 1\n",
    "    test_df['is_train'] = 0\n",
    "    df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "    df = df.sort_values('TransactionDT').reset_index(drop=True)\n",
    "    \n",
    "    for uid in ['uid1', 'uid2']:\n",
    "        # Time since last transaction by this user\n",
    "        df[f'{uid}_time_since_last'] = df.groupby(uid)['TransactionDT'].diff()\n",
    "        df[f'{uid}_time_since_last'] = df[f'{uid}_time_since_last'].fillna(999999)\n",
    "        \n",
    "        # Is this a rapid-fire transaction? (< 1 hour since last)\n",
    "        df[f'{uid}_is_rapid'] = (df[f'{uid}_time_since_last'] < 3600).astype(int)\n",
    "        \n",
    "        # Transaction count in session (cumulative per user)\n",
    "        df[f'{uid}_trans_in_session'] = df.groupby(uid).cumcount()\n",
    "    \n",
    "    # Split back\n",
    "    train_df = df[df['is_train'] == 1].drop('is_train', axis=1)\n",
    "    test_df = df[df['is_train'] == 0].drop('is_train', axis=1)\n",
    "    \n",
    "    del df\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"  ‚úì Created 6 velocity features\")\n",
    "    return train_df, test_df\n",
    "\n",
    "Train_df, Test_df = create_velocity_features(Train_df, Test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üÜï 5.15 Enhanced Frequency Encoding\n",
    "\n",
    "Frequency encoding tells us: **How common is this value?**\n",
    "- Rare cards/emails/devices are more suspicious\n",
    "- We create both raw counts and normalized frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üî• NEW: ENHANCED FREQUENCY ENCODING\n",
    "# ========================================\n",
    "\n",
    "def create_enhanced_frequency_features(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Enhanced frequency encoding with normalization\n",
    "    \"\"\"\n",
    "    print(\"üî• Creating enhanced frequency features...\")\n",
    "    \n",
    "    train_df['is_train'] = 1\n",
    "    test_df['is_train'] = 0\n",
    "    df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    freq_cols = ['uid1', 'uid2', 'uid3', 'uid4', \n",
    "                 'card1', 'card2', 'addr1', 'P_emaildomain',\n",
    "                 'DeviceType', 'DeviceInfo']\n",
    "    \n",
    "    for col in freq_cols:\n",
    "        if col in df.columns:\n",
    "            freq = df[col].value_counts()\n",
    "            df[f'{col}_freq'] = df[col].map(freq)\n",
    "            df[f'{col}_freq_norm'] = df[f'{col}_freq'] / len(df)\n",
    "    \n",
    "    # Split back\n",
    "    train_df = df[df['is_train'] == 1].drop('is_train', axis=1)\n",
    "    test_df = df[df['is_train'] == 0].drop('is_train', axis=1)\n",
    "    \n",
    "    del df\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"  ‚úì Created {len([c for c in freq_cols if c in train_df.columns]) * 2} frequency features\")\n",
    "    return train_df, test_df\n",
    "\n",
    "Train_df, Test_df = create_enhanced_frequency_features(Train_df, Test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üÜï 5.16 Enhanced Feature Engineering Summary\n",
    "\n",
    "### New Features Added:\n",
    "\n",
    "| Category | Features | Purpose |\n",
    "|----------|----------|--------|\n",
    "| UID Magic | 4 UIDs | Identify unique users |\n",
    "| UID Aggregations | 24 features | User behavior patterns |\n",
    "| Velocity | 6 features | Rapid-fire fraud detection |\n",
    "| Frequency | 20 features | How rare is each entity |\n",
    "\n",
    "**Total new features: ~54**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ENHANCED FEATURE ENGINEERING SUMMARY\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üî• ENHANCED FEATURE ENGINEERING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training set shape: {Train_df.shape}\")\n",
    "print(f\"Test set shape: {Test_df.shape}\")\n",
    "print(f\"\\nNew UID-based features created:\")\n",
    "uid_features = [c for c in Train_df.columns if 'uid' in c.lower()]\n",
    "print(f\"  - UID features: {len(uid_features)}\")\n",
    "print(f\"\\nReady for model training with enhanced features!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:41:53.353686Z",
     "iopub.status.busy": "2026-01-25T15:41:53.353342Z",
     "iopub.status.idle": "2026-01-25T15:41:53.444264Z",
     "shell.execute_reply": "2026-01-25T15:41:53.443616Z",
     "shell.execute_reply.started": "2026-01-25T15:41:53.353658Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>P_emaildomain</th>\n",
       "      <th>R_emaildomain</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>D10</th>\n",
       "      <th>D11</th>\n",
       "      <th>D12</th>\n",
       "      <th>D13</th>\n",
       "      <th>D14</th>\n",
       "      <th>D15</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>...</th>\n",
       "      <th>v5_nan_count</th>\n",
       "      <th>v6_sum</th>\n",
       "      <th>v6_mean</th>\n",
       "      <th>v6_std</th>\n",
       "      <th>v6_nan_count</th>\n",
       "      <th>v7_sum</th>\n",
       "      <th>v7_mean</th>\n",
       "      <th>v7_std</th>\n",
       "      <th>v7_nan_count</th>\n",
       "      <th>V_sum_all</th>\n",
       "      <th>V_mean_all</th>\n",
       "      <th>V_std_all</th>\n",
       "      <th>V_nan_count_all</th>\n",
       "      <th>V_nan_ratio</th>\n",
       "      <th>card1_freq</th>\n",
       "      <th>card2_freq</th>\n",
       "      <th>card3_freq</th>\n",
       "      <th>card4_freq</th>\n",
       "      <th>card5_freq</th>\n",
       "      <th>card6_freq</th>\n",
       "      <th>addr1_freq</th>\n",
       "      <th>addr2_freq</th>\n",
       "      <th>P_emaildomain_freq</th>\n",
       "      <th>R_emaildomain_freq</th>\n",
       "      <th>ProductCD_freq</th>\n",
       "      <th>DeviceType_freq</th>\n",
       "      <th>DeviceInfo_freq</th>\n",
       "      <th>card1_TransactionAmt_mean</th>\n",
       "      <th>card1_TransactionAmt_std</th>\n",
       "      <th>card1_TransactionAmt_dev</th>\n",
       "      <th>card2_TransactionAmt_mean</th>\n",
       "      <th>card2_TransactionAmt_std</th>\n",
       "      <th>card2_TransactionAmt_dev</th>\n",
       "      <th>addr1_TransactionAmt_mean</th>\n",
       "      <th>addr1_TransactionAmt_std</th>\n",
       "      <th>addr1_TransactionAmt_dev</th>\n",
       "      <th>id_num_nan_count</th>\n",
       "      <th>id_num_mean</th>\n",
       "      <th>id_num_std</th>\n",
       "      <th>id_12_isFound</th>\n",
       "      <th>id_15_isNew</th>\n",
       "      <th>id_15_isFound</th>\n",
       "      <th>id_16_isFound</th>\n",
       "      <th>id_28_isNew</th>\n",
       "      <th>id_28_isFound</th>\n",
       "      <th>id_29_isFound</th>\n",
       "      <th>id_34_match</th>\n",
       "      <th>id_36_isT</th>\n",
       "      <th>id_37_isT</th>\n",
       "      <th>id_38_isT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>589236</th>\n",
       "      <td>3576236</td>\n",
       "      <td>0</td>\n",
       "      <td>15784983</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>W</td>\n",
       "      <td>15397</td>\n",
       "      <td>465.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>433.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>missing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>449.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>469.0</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>M0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.510418</td>\n",
       "      <td>0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>11.883721</td>\n",
       "      <td>51.654171</td>\n",
       "      <td>0</td>\n",
       "      <td>1288.000000</td>\n",
       "      <td>7.155556</td>\n",
       "      <td>45.442429</td>\n",
       "      <td>159</td>\n",
       "      <td>0.469027</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>521287</td>\n",
       "      <td>384767</td>\n",
       "      <td>296546</td>\n",
       "      <td>439938</td>\n",
       "      <td>7831.0</td>\n",
       "      <td>520481.0</td>\n",
       "      <td>100934</td>\n",
       "      <td>453249</td>\n",
       "      <td>439670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.226921</td>\n",
       "      <td>109.125504</td>\n",
       "      <td>-59.226921</td>\n",
       "      <td>114.196930</td>\n",
       "      <td>224.565094</td>\n",
       "      <td>-85.196930</td>\n",
       "      <td>125.192024</td>\n",
       "      <td>181.264435</td>\n",
       "      <td>-96.192024</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97333</th>\n",
       "      <td>3084333</td>\n",
       "      <td>0</td>\n",
       "      <td>1977021</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>W</td>\n",
       "      <td>2148</td>\n",
       "      <td>480.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>181.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>missing</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>M0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.510418</td>\n",
       "      <td>0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3.255814</td>\n",
       "      <td>12.469186</td>\n",
       "      <td>0</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>1.061111</td>\n",
       "      <td>6.179046</td>\n",
       "      <td>159</td>\n",
       "      <td>0.469027</td>\n",
       "      <td>11</td>\n",
       "      <td>1090</td>\n",
       "      <td>521287</td>\n",
       "      <td>189217</td>\n",
       "      <td>25941</td>\n",
       "      <td>439938</td>\n",
       "      <td>13856.0</td>\n",
       "      <td>520481.0</td>\n",
       "      <td>100934</td>\n",
       "      <td>453249</td>\n",
       "      <td>439670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.633636</td>\n",
       "      <td>65.902176</td>\n",
       "      <td>-68.633636</td>\n",
       "      <td>147.520050</td>\n",
       "      <td>217.137680</td>\n",
       "      <td>-88.520050</td>\n",
       "      <td>151.716980</td>\n",
       "      <td>233.640182</td>\n",
       "      <td>-92.716980</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343940</th>\n",
       "      <td>3330940</td>\n",
       "      <td>0</td>\n",
       "      <td>8471385</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>W</td>\n",
       "      <td>16869</td>\n",
       "      <td>555.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>missing</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.510418</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.396450</td>\n",
       "      <td>0.490614</td>\n",
       "      <td>170</td>\n",
       "      <td>0.501475</td>\n",
       "      <td>6</td>\n",
       "      <td>41995</td>\n",
       "      <td>521287</td>\n",
       "      <td>384767</td>\n",
       "      <td>296546</td>\n",
       "      <td>439938</td>\n",
       "      <td>23078.0</td>\n",
       "      <td>520481.0</td>\n",
       "      <td>45250</td>\n",
       "      <td>453249</td>\n",
       "      <td>439670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.625000</td>\n",
       "      <td>70.475479</td>\n",
       "      <td>-46.674999</td>\n",
       "      <td>125.703545</td>\n",
       "      <td>205.944016</td>\n",
       "      <td>-72.753540</td>\n",
       "      <td>134.430649</td>\n",
       "      <td>238.724823</td>\n",
       "      <td>-81.480652</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110197</th>\n",
       "      <td>3097197</td>\n",
       "      <td>1</td>\n",
       "      <td>2157020</td>\n",
       "      <td>139.220001</td>\n",
       "      <td>C</td>\n",
       "      <td>4606</td>\n",
       "      <td>141.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>137.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>924.0</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.296450</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0</td>\n",
       "      <td>6145.256836</td>\n",
       "      <td>21.869242</td>\n",
       "      <td>107.557617</td>\n",
       "      <td>58</td>\n",
       "      <td>0.171091</td>\n",
       "      <td>50</td>\n",
       "      <td>279</td>\n",
       "      <td>56346</td>\n",
       "      <td>384767</td>\n",
       "      <td>11720</td>\n",
       "      <td>148986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45250</td>\n",
       "      <td>27509</td>\n",
       "      <td>68519</td>\n",
       "      <td>85165.0</td>\n",
       "      <td>47722.0</td>\n",
       "      <td>46.701160</td>\n",
       "      <td>37.033875</td>\n",
       "      <td>92.518845</td>\n",
       "      <td>44.465210</td>\n",
       "      <td>37.006374</td>\n",
       "      <td>94.754791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>26689.554688</td>\n",
       "      <td>80042.789062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464853</th>\n",
       "      <td>3451853</td>\n",
       "      <td>0</td>\n",
       "      <td>11973255</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>H</td>\n",
       "      <td>14649</td>\n",
       "      <td>548.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>272.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.541672</td>\n",
       "      <td>0.541666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.469903</td>\n",
       "      <td>94</td>\n",
       "      <td>0.277286</td>\n",
       "      <td>862</td>\n",
       "      <td>1082</td>\n",
       "      <td>521287</td>\n",
       "      <td>384767</td>\n",
       "      <td>296546</td>\n",
       "      <td>439938</td>\n",
       "      <td>20141.0</td>\n",
       "      <td>520481.0</td>\n",
       "      <td>228355</td>\n",
       "      <td>11842</td>\n",
       "      <td>33024</td>\n",
       "      <td>85165.0</td>\n",
       "      <td>12573.0</td>\n",
       "      <td>104.087914</td>\n",
       "      <td>149.851013</td>\n",
       "      <td>-79.087914</td>\n",
       "      <td>117.673813</td>\n",
       "      <td>160.665665</td>\n",
       "      <td>-92.673813</td>\n",
       "      <td>130.983261</td>\n",
       "      <td>216.018448</td>\n",
       "      <td>-105.983261</td>\n",
       "      <td>2</td>\n",
       "      <td>3783.333252</td>\n",
       "      <td>11311.798828</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  \\\n",
       "589236        3576236        0       15784983       29.000000         W   \n",
       "97333         3084333        0        1977021       59.000000         W   \n",
       "343940        3330940        0        8471385       52.950001         W   \n",
       "110197        3097197        1        2157020      139.220001         C   \n",
       "464853        3451853        0       11973255       25.000000         H   \n",
       "\n",
       "        card1  card2  card3       card4  card5   card6  addr1  addr2  dist1  \\\n",
       "589236  15397  465.0  150.0        visa  226.0   debit  433.0   87.0  535.0   \n",
       "97333    2148  480.0  150.0  mastercard  117.0   debit  181.0   87.0   13.0   \n",
       "343940  16869  555.0  150.0        visa  226.0   debit  315.0   87.0    NaN   \n",
       "110197   4606  141.0  185.0        visa  137.0  credit    NaN    NaN    NaN   \n",
       "464853  14649  548.0  150.0        visa  226.0   debit  272.0   87.0    NaN   \n",
       "\n",
       "        dist2 P_emaildomain R_emaildomain   C1   C2   C3   C4   C5   C6   C7  \\\n",
       "589236    NaN     yahoo.com       missing  3.0  4.0  0.0  0.0  1.0  2.0  0.0   \n",
       "97333     NaN     yahoo.com       missing  2.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "343940    NaN   hotmail.com       missing  5.0  4.0  0.0  0.0  2.0  5.0  0.0   \n",
       "110197  924.0   hotmail.com   hotmail.com  8.0  9.0  0.0  1.0  0.0  1.0  1.0   \n",
       "464853    NaN     gmail.com     yahoo.com  1.0  1.0  0.0  1.0  0.0  1.0  0.0   \n",
       "\n",
       "         C8   C9  C10  C11  C12   C13  C14     D1     D2    D3     D4     D5  \\\n",
       "589236  0.0  5.0  0.0  3.0  1.0  71.0  2.0  469.0  469.0  11.0  469.0   11.0   \n",
       "97333   0.0  1.0  0.0  1.0  0.0   2.0  2.0    0.0    NaN   NaN   24.0   24.0   \n",
       "343940  0.0  2.0  0.0  2.0  0.0  15.0  5.0    0.0    NaN   NaN  131.0  131.0   \n",
       "110197  3.0  0.0  3.0  2.0  2.0   0.0  0.0    0.0    NaN   NaN    2.0    0.0   \n",
       "464853  1.0  0.0  1.0  1.0  0.0   1.0  1.0    0.0    NaN   NaN    NaN    NaN   \n",
       "\n",
       "         D6   D7          D8        D9    D10    D11  D12  D13  D14    D15  \\\n",
       "589236  NaN  NaN         NaN       NaN  449.0  469.0  NaN  NaN  NaN  469.0   \n",
       "97333   NaN  NaN         NaN       NaN   24.0   24.0  NaN  NaN  NaN   24.0   \n",
       "343940  NaN  NaN         NaN       NaN  131.0    NaN  NaN  NaN  NaN  131.0   \n",
       "110197  2.0  0.0    6.958333  0.958333    0.0    NaN  2.0  1.0  0.0    2.0   \n",
       "464853  NaN  NaN  180.541672  0.541666    NaN    NaN  NaN  NaN  0.0    NaN   \n",
       "\n",
       "         M1   M2   M3   M4  ... v5_nan_count v6_sum v6_mean    v6_std  \\\n",
       "589236    T    T    T   M0  ...            0    9.0    0.45  0.510418   \n",
       "97333     T    T    T   M0  ...            0    9.0    0.45  0.510418   \n",
       "343940  NaN  NaN  NaN  NaN  ...            0   11.0    0.55  0.510418   \n",
       "110197  NaN  NaN  NaN   M2  ...            0   34.0    1.70  2.296450   \n",
       "464853  NaN  NaN  NaN  NaN  ...           22    0.0     NaN       NaN   \n",
       "\n",
       "       v6_nan_count  v7_sum    v7_mean     v7_std  v7_nan_count    V_sum_all  \\\n",
       "589236            0   511.0  11.883721  51.654171             0  1288.000000   \n",
       "97333             0   140.0   3.255814  12.469186             0   191.000000   \n",
       "343940            0    19.0   0.441860   0.502486             0    67.000000   \n",
       "110197            0    19.0   0.441860   0.502486             0  6145.256836   \n",
       "464853           20    19.0   0.441860   0.502486             0    80.000000   \n",
       "\n",
       "        V_mean_all   V_std_all  V_nan_count_all  V_nan_ratio  card1_freq  \\\n",
       "589236    7.155556   45.442429              159     0.469027          78   \n",
       "97333     1.061111    6.179046              159     0.469027          11   \n",
       "343940    0.396450    0.490614              170     0.501475           6   \n",
       "110197   21.869242  107.557617               58     0.171091          50   \n",
       "464853    0.326531    0.469903               94     0.277286         862   \n",
       "\n",
       "        card2_freq  card3_freq  card4_freq  card5_freq  card6_freq  \\\n",
       "589236          88      521287      384767      296546      439938   \n",
       "97333         1090      521287      189217       25941      439938   \n",
       "343940       41995      521287      384767      296546      439938   \n",
       "110197         279       56346      384767       11720      148986   \n",
       "464853        1082      521287      384767      296546      439938   \n",
       "\n",
       "        addr1_freq  addr2_freq  P_emaildomain_freq  R_emaildomain_freq  \\\n",
       "589236      7831.0    520481.0              100934              453249   \n",
       "97333      13856.0    520481.0              100934              453249   \n",
       "343940     23078.0    520481.0               45250              453249   \n",
       "110197         NaN         NaN               45250               27509   \n",
       "464853     20141.0    520481.0              228355               11842   \n",
       "\n",
       "        ProductCD_freq  DeviceType_freq  DeviceInfo_freq  \\\n",
       "589236          439670              NaN              NaN   \n",
       "97333           439670              NaN              NaN   \n",
       "343940          439670              NaN              NaN   \n",
       "110197           68519          85165.0          47722.0   \n",
       "464853           33024          85165.0          12573.0   \n",
       "\n",
       "        card1_TransactionAmt_mean  card1_TransactionAmt_std  \\\n",
       "589236                  88.226921                109.125504   \n",
       "97333                  127.633636                 65.902176   \n",
       "343940                  99.625000                 70.475479   \n",
       "110197                  46.701160                 37.033875   \n",
       "464853                 104.087914                149.851013   \n",
       "\n",
       "        card1_TransactionAmt_dev  card2_TransactionAmt_mean  \\\n",
       "589236                -59.226921                 114.196930   \n",
       "97333                 -68.633636                 147.520050   \n",
       "343940                -46.674999                 125.703545   \n",
       "110197                 92.518845                  44.465210   \n",
       "464853                -79.087914                 117.673813   \n",
       "\n",
       "        card2_TransactionAmt_std  card2_TransactionAmt_dev  \\\n",
       "589236                224.565094                -85.196930   \n",
       "97333                 217.137680                -88.520050   \n",
       "343940                205.944016                -72.753540   \n",
       "110197                 37.006374                 94.754791   \n",
       "464853                160.665665                -92.673813   \n",
       "\n",
       "        addr1_TransactionAmt_mean  addr1_TransactionAmt_std  \\\n",
       "589236                 125.192024                181.264435   \n",
       "97333                  151.716980                233.640182   \n",
       "343940                 134.430649                238.724823   \n",
       "110197                        NaN                       NaN   \n",
       "464853                 130.983261                216.018448   \n",
       "\n",
       "        addr1_TransactionAmt_dev  id_num_nan_count   id_num_mean  \\\n",
       "589236                -96.192024                11           NaN   \n",
       "97333                 -92.716980                11           NaN   \n",
       "343940                -81.480652                11           NaN   \n",
       "110197                       NaN                 2  26689.554688   \n",
       "464853               -105.983261                 2   3783.333252   \n",
       "\n",
       "          id_num_std  id_12_isFound  id_15_isNew  id_15_isFound  \\\n",
       "589236           NaN              0            0              0   \n",
       "97333            NaN              0            0              0   \n",
       "343940           NaN              0            0              0   \n",
       "110197  80042.789062              0            0              1   \n",
       "464853  11311.798828              0            0              1   \n",
       "\n",
       "        id_16_isFound  id_28_isNew  id_28_isFound  id_29_isFound  id_34_match  \\\n",
       "589236              0            0              0              0           -1   \n",
       "97333               0            0              0              0           -1   \n",
       "343940              0            0              0              0           -1   \n",
       "110197              1            0              1              1           -1   \n",
       "464853              1            0              1              1            2   \n",
       "\n",
       "        id_36_isT  id_37_isT  id_38_isT  \n",
       "589236          0          0          0  \n",
       "97333           0          0          0  \n",
       "343940          0          0          0  \n",
       "110197          0          1          1  \n",
       "464853          0          1          1  \n",
       "\n",
       "[5 rows x 569 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6** : Data preprocessing for The model\n",
    "\n",
    "1. Seperate Features(X_train) and target(y_train)\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:44:27.519948Z",
     "iopub.status.busy": "2026-01-25T15:44:27.519545Z",
     "iopub.status.idle": "2026-01-25T15:44:27.526809Z",
     "shell.execute_reply": "2026-01-25T15:44:27.525639Z",
     "shell.execute_reply.started": "2026-01-25T15:44:27.519915Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (103524326.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_55/103524326.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    from sklearn.preprocessing import StandardScaler, OrdinalEncoder()\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "v_cols = [i for i in Train_df.columns if 'v' in i.lower() and i[1:].isdigit()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "v_pca = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=0.95, svd_solver='full')\n",
    ")\n",
    "\n",
    "\n",
    "transformed_v_pca = v_pca.fit_transform(Train_df[v_cols])\n",
    "transformed_v_pca.shape, len(v_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:47:10.661303Z",
     "iopub.status.busy": "2026-01-25T15:47:10.660572Z",
     "iopub.status.idle": "2026-01-25T15:47:53.473837Z",
     "shell.execute_reply": "2026-01-25T15:47:53.473150Z",
     "shell.execute_reply.started": "2026-01-25T15:47:10.661270Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Preprocessing complete! Train shape: (531486, 327)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# The rest of your existing imports\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def local_data_preprocessor(df):\n",
    "    print(\"Starting preprocessing...\")\n",
    "    \n",
    "    y = df['isFraud']\n",
    "    X = df.drop('isFraud', axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, shuffle=True, random_state=6\n",
    "    )\n",
    "\n",
    "    # Note: select_dtypes(include=['object', 'category']) covers both string and category types\n",
    "    cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # V columns selection\n",
    "    v_cols = [c for c in X_train.columns if c.startswith('V')]\n",
    "    \n",
    "    # Numerical columns (Exclude V columns)\n",
    "    num_cols = [c for c in X_train.select_dtypes(include=np.number).columns.tolist() if c not in v_cols]\n",
    "    \n",
    "    # Transformers\n",
    "    num_transformer = SimpleImputer(strategy='constant', fill_value=-999)\n",
    "    \n",
    "    cat_transformer = OrdinalEncoder(\n",
    "        handle_unknown='use_encoded_value', \n",
    "        unknown_value=-1,\n",
    "        encoded_missing_value=-999\n",
    "    )\n",
    "\n",
    "    v_pca = make_pipeline(\n",
    "        SimpleImputer(strategy='mean'),\n",
    "        StandardScaler(),\n",
    "        PCA(n_components=0.96, svd_solver='full')\n",
    "    )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols),\n",
    "            ('cat', cat_transformer, cat_cols),\n",
    "            ('pca', v_pca, v_cols)\n",
    "        ],\n",
    "        remainder='drop', # Changed to drop to be safe, or 'passthrough' if you are sure\n",
    "        verbose_feature_names_out=False\n",
    "    ).set_output(transform=\"pandas\")\n",
    "    \n",
    "    # Apply\n",
    "    # Fit on Train only\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "    # using only transform to avoide data leakage\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "    \n",
    "    print(f\"Preprocessing complete! Train shape: {X_train_processed.shape}\")\n",
    "\n",
    "    return X_train_processed, X_test_processed, y_train, y_test\n",
    "\n",
    "# Usage\n",
    "X_train, X_test, y_train, y_test = local_data_preprocessor(Train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7** Model Trainig :\n",
    "\n",
    "### ok so im using LightGBM(for speed) and XGboost(robust king) so yeah let see the auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T16:02:17.739759Z",
     "iopub.status.busy": "2026-01-25T16:02:17.739028Z",
     "iopub.status.idle": "2026-01-25T16:02:17.748513Z",
     "shell.execute_reply": "2026-01-25T16:02:17.747848Z",
     "shell.execute_reply.started": "2026-01-25T16:02:17.739730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def train_models(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    lgbm_params = {\n",
    "    'objective': 'binary',          # It's a Yes/No problem\n",
    "    'metric': 'auc',                # Competition metric is ROC-AUC\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    # --- Imbalance Handling ---\n",
    "    'is_unbalance': True,           # Critical: Tells model fraud is rare\n",
    "    # Alternative: 'scale_pos_weight': 9  (If you don't use is_unbalance)\n",
    "    \n",
    "    # --- Complexity (The most important part) ---\n",
    "    'num_leaves': 256,              # High value because we have lots of data\n",
    "    'min_data_in_leaf': 40,         # Stop splitting if node is too small (prevents overfitting)\n",
    "    'max_depth': -1,                # No limit, let num_leaves control depth\n",
    "    \n",
    "    # --- Speed & Regularization ---\n",
    "    'learning_rate': 0.01,          # Go slow! (Standard is 0.1, 0.01 is better for accuracy)\n",
    "    'n_estimators': 2000,           # Lots of trees because learning_rate is low\n",
    "    \n",
    "    # --- Randomness (to prevent overfitting) ---\n",
    "    'feature_fraction': 0.7,        # Use 70% of columns per tree\n",
    "    'bagging_fraction': 0.7,        # Use 70% of rows per tree\n",
    "    'bagging_freq': 1,              # Perform bagging every k iterations\n",
    "    \n",
    "    # --- Hardware ---\n",
    "    'device': 'gpu',                # Use GPU if available\n",
    "    'n_jobs': -1                    # Use all CPU cores\n",
    "    }\n",
    "    \n",
    "    xgb_params = {\n",
    "        # --- Core Type ---\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        \n",
    "        # --- The Fix for \"Invalid Input: gpu_hist\" ---\n",
    "        'tree_method': 'hist',      # Use 'hist' (fastest algorithm)\n",
    "        'device': 'cuda',           # Enable GPU here (use 'cpu' if no GPU)\n",
    "        \n",
    "        # --- Imbalance Handling (Crucial for Fraud) ---\n",
    "        # IEEE-CIS mein ~3.5% fraud hai. Ratio approx 27:1 hai.\n",
    "        'scale_pos_weight': 27,     \n",
    "        \n",
    "        # --- Complexity & Overfitting ---\n",
    "        'max_depth': 10,            # Thoda deep rakha hai kyuki fraud patterns complex hote hain\n",
    "        'min_child_weight': 5,      # Noise kam karne ke liye (conservative setting)\n",
    "        \n",
    "        # --- Speed & Sampling (prevent overfitting) ---\n",
    "        'learning_rate': 0.02,      # Slow learning for better accuracy\n",
    "        'n_estimators': 3000,       # High number, rely on Early Stopping\n",
    "        'subsample': 0.8,           # Har tree ke liye 80% data use karega\n",
    "        'colsample_bytree': 0.7,    # Har split ke liye 70% features check karega\n",
    "        \n",
    "        # --- Regularization (L1/L2) ---\n",
    "        'reg_alpha': 1,             # L1 (Lasso) - Useless features ko 0 kar deta hai\n",
    "        'reg_lambda': 2             # L2 (Ridge) - Weights ko control mein rakhta hai\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "     # XGB\n",
    "    clf_xgb = XGBClassifier(**xgb_params)\n",
    "    \n",
    "    # Train with Monitoring\n",
    "    clf_xgb.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "        # Verbose=50 means \"print every 50 trees\"\n",
    "        verbose=50 \n",
    "    )\n",
    "    \n",
    "    # 3. See Score History After Training\n",
    "    results = clf_xgb.evals_result()\n",
    "    # results['validation_0']['auc'] contains the history\n",
    "    print(f\"Final AUC: {results['validation_1']['auc'][-1]}\")\n",
    "    \n",
    "    # 1. Initialize\n",
    "    clf_lgbm = LGBMClassifier(**lgbm_params) # Unpack your params dict\n",
    "    \n",
    "    # 2. Train with Monitoring\n",
    "    clf_lgbm.fit(\n",
    "        X_train, y_train,\n",
    "        # Pass the test set here to see scores on it\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)], \n",
    "        eval_names=['Training', 'Validation'],\n",
    "        eval_metric='auc',\n",
    "        \n",
    "        # OUTPUT CONTROL:\n",
    "        # early_stopping(100): Stop if score doesn't improve for 100 rounds\n",
    "        # log_evaluation(50): Print score every 50 rounds (prevents screen spam)\n",
    "        callbacks=[early_stopping(stopping_rounds=100), log_evaluation(50)]\n",
    "    )\n",
    "    \n",
    "    # 3. See Best Score After Training\n",
    "    print(f\"Best Iteration: {clf_lgbm.best_iteration_}\")\n",
    "    print(f\"Best Score (Validation): {clf_lgbm.best_score_['Validation']['auc']}\")\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "    return clf_lgbm,clf_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T16:02:20.049731Z",
     "iopub.status.busy": "2026-01-25T16:02:20.049240Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.89757\tvalidation_1-auc:0.86165\n",
      "[50]\tvalidation_0-auc:0.95510\tvalidation_1-auc:0.92577\n",
      "[100]\tvalidation_0-auc:0.96718\tvalidation_1-auc:0.93583\n",
      "[150]\tvalidation_0-auc:0.97642\tvalidation_1-auc:0.94317\n",
      "[200]\tvalidation_0-auc:0.98253\tvalidation_1-auc:0.94904\n",
      "[250]\tvalidation_0-auc:0.98684\tvalidation_1-auc:0.95251\n",
      "[300]\tvalidation_0-auc:0.98972\tvalidation_1-auc:0.95503\n",
      "[350]\tvalidation_0-auc:0.99176\tvalidation_1-auc:0.95679\n",
      "[400]\tvalidation_0-auc:0.99372\tvalidation_1-auc:0.95842\n",
      "[450]\tvalidation_0-auc:0.99510\tvalidation_1-auc:0.95975\n",
      "[500]\tvalidation_0-auc:0.99613\tvalidation_1-auc:0.96081\n",
      "[550]\tvalidation_0-auc:0.99703\tvalidation_1-auc:0.96184\n",
      "[600]\tvalidation_0-auc:0.99764\tvalidation_1-auc:0.96257\n",
      "[650]\tvalidation_0-auc:0.99819\tvalidation_1-auc:0.96330\n",
      "[700]\tvalidation_0-auc:0.99861\tvalidation_1-auc:0.96388\n",
      "[750]\tvalidation_0-auc:0.99893\tvalidation_1-auc:0.96455\n",
      "[800]\tvalidation_0-auc:0.99918\tvalidation_1-auc:0.96506\n",
      "[850]\tvalidation_0-auc:0.99938\tvalidation_1-auc:0.96554\n",
      "[900]\tvalidation_0-auc:0.99952\tvalidation_1-auc:0.96599\n",
      "[950]\tvalidation_0-auc:0.99963\tvalidation_1-auc:0.96637\n",
      "[1000]\tvalidation_0-auc:0.99971\tvalidation_1-auc:0.96673\n",
      "[1050]\tvalidation_0-auc:0.99978\tvalidation_1-auc:0.96709\n",
      "[1100]\tvalidation_0-auc:0.99983\tvalidation_1-auc:0.96740\n",
      "[1150]\tvalidation_0-auc:0.99987\tvalidation_1-auc:0.96774\n",
      "[1200]\tvalidation_0-auc:0.99990\tvalidation_1-auc:0.96800\n",
      "[1250]\tvalidation_0-auc:0.99992\tvalidation_1-auc:0.96835\n",
      "[1300]\tvalidation_0-auc:0.99994\tvalidation_1-auc:0.96856\n",
      "[1350]\tvalidation_0-auc:0.99995\tvalidation_1-auc:0.96868\n",
      "[1400]\tvalidation_0-auc:0.99996\tvalidation_1-auc:0.96892\n",
      "[1450]\tvalidation_0-auc:0.99997\tvalidation_1-auc:0.96917\n",
      "[1500]\tvalidation_0-auc:0.99998\tvalidation_1-auc:0.96942\n",
      "[1550]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.96963\n",
      "[1600]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.96981\n",
      "[1650]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.97002\n",
      "[1700]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.97020\n",
      "[1750]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.97034\n",
      "[1800]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97059\n",
      "[1850]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97071\n",
      "[1900]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97076\n",
      "[1950]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97087\n",
      "[2000]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97106\n",
      "[2050]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97120\n",
      "[2100]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97133\n",
      "[2150]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97141\n",
      "[2200]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97146\n",
      "[2250]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97155\n",
      "[2300]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97163\n",
      "[2350]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97165\n",
      "[2400]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97168\n",
      "[2450]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97183\n",
      "[2500]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97190\n",
      "[2550]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97195\n",
      "[2600]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97200\n",
      "[2650]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97211\n",
      "[2700]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97212\n",
      "[2750]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97219\n",
      "[2800]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97220\n",
      "[2850]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97219\n",
      "[2900]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97222\n",
      "[2950]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97226\n",
      "[2999]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.97222\n",
      "Final AUC: 0.9722216598637835\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 18539, number of negative: 512947\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 49573\n",
      "[LightGBM] [Info] Number of data points in the train set: 531486, number of used features: 327\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 206 dense feature groups (105.43 MB) transferred to GPU in 0.117127 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.034881 -> initscore=-3.320296\n",
      "[LightGBM] [Info] Start training from score -3.320296\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tTraining's auc: 0.96491\tValidation's auc: 0.930877\n",
      "[100]\tTraining's auc: 0.972441\tValidation's auc: 0.935701\n",
      "[150]\tTraining's auc: 0.976899\tValidation's auc: 0.939353\n",
      "[200]\tTraining's auc: 0.980158\tValidation's auc: 0.941851\n",
      "[250]\tTraining's auc: 0.983291\tValidation's auc: 0.944599\n",
      "[300]\tTraining's auc: 0.986036\tValidation's auc: 0.947389\n",
      "[350]\tTraining's auc: 0.98833\tValidation's auc: 0.949974\n",
      "[400]\tTraining's auc: 0.990266\tValidation's auc: 0.952229\n",
      "[450]\tTraining's auc: 0.991833\tValidation's auc: 0.95402\n",
      "[500]\tTraining's auc: 0.99317\tValidation's auc: 0.955886\n",
      "[550]\tTraining's auc: 0.994298\tValidation's auc: 0.957193\n"
     ]
    }
   ],
   "source": [
    "train_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:48:29.487693Z",
     "iopub.status.busy": "2026-01-25T15:48:29.487076Z",
     "iopub.status.idle": "2026-01-25T15:56:38.158898Z",
     "shell.execute_reply": "2026-01-25T15:56:38.157860Z",
     "shell.execute_reply.started": "2026-01-25T15:48:29.487660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 18539, number of negative: 512947\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 49573\n",
      "[LightGBM] [Info] Number of data points in the train set: 531486, number of used features: 327\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 206 dense feature groups (105.43 MB) transferred to GPU in 0.111475 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.034881 -> initscore=-3.320296\n",
      "[LightGBM] [Info] Start training from score -3.320296\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tTraining's auc: 0.964904\tValidation's auc: 0.930798\n",
      "[100]\tTraining's auc: 0.972457\tValidation's auc: 0.935503\n",
      "[150]\tTraining's auc: 0.97686\tValidation's auc: 0.939114\n",
      "[200]\tTraining's auc: 0.980192\tValidation's auc: 0.94182\n",
      "[250]\tTraining's auc: 0.983354\tValidation's auc: 0.944651\n",
      "[300]\tTraining's auc: 0.986095\tValidation's auc: 0.947559\n",
      "[350]\tTraining's auc: 0.988401\tValidation's auc: 0.95029\n",
      "[400]\tTraining's auc: 0.99034\tValidation's auc: 0.95246\n",
      "[450]\tTraining's auc: 0.9919\tValidation's auc: 0.954314\n",
      "[500]\tTraining's auc: 0.993224\tValidation's auc: 0.956101\n",
      "[550]\tTraining's auc: 0.994342\tValidation's auc: 0.957292\n",
      "[600]\tTraining's auc: 0.995235\tValidation's auc: 0.958486\n",
      "[650]\tTraining's auc: 0.995973\tValidation's auc: 0.959348\n",
      "[700]\tTraining's auc: 0.996582\tValidation's auc: 0.960153\n",
      "[750]\tTraining's auc: 0.99711\tValidation's auc: 0.961002\n",
      "[800]\tTraining's auc: 0.997525\tValidation's auc: 0.961701\n",
      "[850]\tTraining's auc: 0.997879\tValidation's auc: 0.962295\n",
      "[900]\tTraining's auc: 0.998186\tValidation's auc: 0.962944\n",
      "[950]\tTraining's auc: 0.998439\tValidation's auc: 0.963439\n",
      "[1000]\tTraining's auc: 0.998663\tValidation's auc: 0.963983\n",
      "[1050]\tTraining's auc: 0.998837\tValidation's auc: 0.964326\n",
      "[1100]\tTraining's auc: 0.998992\tValidation's auc: 0.964738\n",
      "[1150]\tTraining's auc: 0.999127\tValidation's auc: 0.965035\n",
      "[1200]\tTraining's auc: 0.999243\tValidation's auc: 0.965437\n",
      "[1250]\tTraining's auc: 0.999339\tValidation's auc: 0.965794\n",
      "[1300]\tTraining's auc: 0.999426\tValidation's auc: 0.966163\n",
      "[1350]\tTraining's auc: 0.999501\tValidation's auc: 0.966404\n",
      "[1400]\tTraining's auc: 0.999566\tValidation's auc: 0.966675\n",
      "[1450]\tTraining's auc: 0.999624\tValidation's auc: 0.966869\n",
      "[1500]\tTraining's auc: 0.999672\tValidation's auc: 0.967078\n",
      "[1550]\tTraining's auc: 0.999716\tValidation's auc: 0.967238\n",
      "[1600]\tTraining's auc: 0.99975\tValidation's auc: 0.967524\n",
      "[1650]\tTraining's auc: 0.99978\tValidation's auc: 0.967762\n",
      "[1700]\tTraining's auc: 0.999809\tValidation's auc: 0.967959\n",
      "[1750]\tTraining's auc: 0.999834\tValidation's auc: 0.968167\n",
      "[1800]\tTraining's auc: 0.999858\tValidation's auc: 0.968296\n",
      "[1850]\tTraining's auc: 0.999877\tValidation's auc: 0.968412\n",
      "[1900]\tTraining's auc: 0.999895\tValidation's auc: 0.968473\n",
      "[1950]\tTraining's auc: 0.999911\tValidation's auc: 0.968591\n",
      "[2000]\tTraining's auc: 0.999924\tValidation's auc: 0.968739\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1998]\tTraining's auc: 0.999923\tValidation's auc: 0.968742\n",
      "Best Iteration: 1998\n",
      "Best Score (Validation): 0.9687417693053517\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "Invalid Input: 'gpu_hist', valid values are: {'approx', 'auto', 'exact', 'hist'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/2988450671.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_55/1703947756.py\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# 2. Train with Monitoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     clf_xgb.fit(\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1801\u001b[0m             )\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1803\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1804\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2433\u001b[0;31m             _check_call(\n\u001b[0m\u001b[1;32m   2434\u001b[0m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[1;32m   2435\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: Invalid Input: 'gpu_hist', valid values are: {'approx', 'auto', 'exact', 'hist'}"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-25T15:42:22.618025Z",
     "iopub.status.idle": "2026-01-25T15:42:22.618336Z",
     "shell.execute_reply": "2026-01-25T15:42:22.618189Z",
     "shell.execute_reply.started": "2026-01-25T15:42:22.618173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrices import ClassificationReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 568274,
     "sourceId": 14242,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
